This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
__tests__/App.test.tsx
.eslintrc.js
.gitignore
.prettierrc.js
.watchmanconfig
android/app/build.gradle
android/app/proguard-rules.pro
android/app/src/debug/AndroidManifest.xml
android/app/src/main/AndroidManifest.xml
android/app/src/main/java/com/merchantapp2/MainActivity.kt
android/app/src/main/java/com/merchantapp2/MainApplication.kt
android/app/src/main/res/drawable/rn_edit_text_material.xml
android/app/src/main/res/values/strings.xml
android/app/src/main/res/values/styles.xml
android/build.gradle
android/gradle.properties
android/gradle/wrapper/gradle-wrapper.properties
android/gradlew
android/gradlew.bat
android/settings.gradle
app.json
App.tsx
babel.config.js
ERROR_FIX_SUMMARY.md
FACE_RECOGNITION_SETUP.md
Gemfile
IMPLEMENTATION_SUMMARY.md
index.js
ios/.xcode.env
ios/MerchantApp2.xcodeproj/project.pbxproj
ios/MerchantApp2.xcodeproj/xcshareddata/xcschemes/MerchantApp2.xcscheme
ios/MerchantApp2/AppDelegate.swift
ios/MerchantApp2/Images.xcassets/AppIcon.appiconset/Contents.json
ios/MerchantApp2/Images.xcassets/Contents.json
ios/MerchantApp2/Info.plist
ios/MerchantApp2/LaunchScreen.storyboard
ios/MerchantApp2/PrivacyInfo.xcprivacy
ios/Podfile
jest.config.js
metro.config.js
package.json
QR_SCANNER_TESTING.md
README.md
REAL_TIME_FACE_DETECTION_GUIDE.md
src/FaceScanner.tsx
src/QRCodeGenerator.tsx
src/QrScanner.tsx
src/screens/Dashboard.tsx
src/screens/PaymentScreen.tsx
src/services/faceRecognitionApi.ts
src/services/mockApi.ts
src/types.ts
src/utils/imageProcessing.ts
src/utils/QRCodeGenerator.tsx
TESTING_GUIDE.md
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="ERROR_FIX_SUMMARY.md">
# Error Fix Summary

## üêõ **What Was Wrong:**
The app was crashing with a module resolution error because:

1. **Missing TensorFlow.js Dependencies** - The app was trying to import TensorFlow.js modules that weren't properly installed
2. **Complex Skia Operations** - The image processing function was using advanced Skia operations that might not be compatible
3. **Import Path Issues** - TensorFlow.js React Native platform wasn't available in the npm registry

## ‚úÖ **What I Fixed:**

### 1. **Removed Problematic Dependencies**
- Removed `@tensorflow/tfjs-react-native` which was causing module resolution errors
- Commented out all TensorFlow.js imports temporarily

### 2. **Simplified FaceScanner.tsx**
- Replaced TensorFlow.js imports with comments for future implementation
- Simplified the model loading logic
- Replaced complex image processing calls with placeholders
- Kept the core functionality working

### 3. **Simplified Image Processing**
- Replaced complex Skia operations with placeholder implementation
- Added proper error handling and fallbacks
- Maintained the function signatures for future implementation

### 4. **Maintained Core Features**
- ‚úÖ Camera integration still works
- ‚úÖ Face detection simulation still works
- ‚úÖ UI/UX remains intact
- ‚úÖ Navigation works properly
- ‚úÖ Error handling is in place

## üöÄ **Current Status:**
The app now runs successfully with:
- **Working camera** with front-facing view
- **Face detection simulation** (tap "Detect Face" button)
- **Image capture** functionality
- **Professional UI** with loading states
- **Placeholder processing** pipeline ready for implementation

## üéØ **Next Steps for Full Implementation:**

### **Option 1: Simple Implementation (Recommended)**
```bash
# Install a more compatible face detection library
npm install @react-native-ml-kit/face-detection
```

### **Option 2: TensorFlow.js Implementation**
```bash
# Install core TensorFlow.js packages (when ready)
npm install @tensorflow/tfjs @tensorflow/tfjs-bundle-type
```

### **Option 3: Custom Implementation**
- Use native Android/iOS face detection APIs
- Implement through React Native bridges

## üì± **How to Test:**
1. Open the app
2. Navigate to "Face Recognition" from dashboard
3. Grant camera permissions
4. Tap "Detect Face" to simulate detection
5. Tap "Recognize Face" to test the processing pipeline
6. Check console logs for processing steps

The app is now stable and ready for real face detection implementation!
</file>

<file path="FACE_RECOGNITION_SETUP.md">
# Face Recognition Setup Guide

This guide will help you set up the face recognition feature in your React Native application.

## üì¶ Required Libraries

You need to install the following packages:

```bash
npm install vision-camera-face-detector @shopify/react-native-skia @tensorflow/tfjs-react-native
```

### Library Details:

1. **vision-camera-face-detector** - Face detection plugin for react-native-vision-camera
2. **@tensorflow/tfjs-react-native** - TensorFlow.js for React Native (machine learning)
3. **@shopify/react-native-skia** - Graphics library for image processing

## üîß Installation Steps

### 1. Install Dependencies

```bash
npm install vision-camera-face-detector @shopify/react-native-skia @tensorflow/tfjs-react-native
```

### 2. iOS Setup (if applicable)

For iOS, you'll need to install pods:

```bash
cd ios && pod install && cd ..
```

### 3. Android Setup

For Android, you may need to update your `android/app/build.gradle` to include TensorFlow Lite dependencies.

### 4. Add TensorFlow.js Model

1. Download a FaceNet model (`.json` and `.bin` files for TensorFlow.js)
2. Place it in your project's assets folder
3. Update the model path in `FaceScanner.tsx`

## üöÄ Implementation Steps

### Step 1: Update Navigation

The `FaceScanner` screen has been added to your navigation types. You can now navigate to it:

```typescript
navigation.navigate('FaceScanner');
```

### Step 2: Implement Image Processing

The current implementation includes placeholders for image processing. You need to implement the `cropAndPreprocessImage` function in `src/utils/imageProcessing.ts` using react-native-skia.

### Step 3: Configure TensorFlow.js

1. Uncomment the TensorFlow.js import in `FaceScanner.tsx`
2. Update the model path to point to your `.json` model file
3. Implement the inference logic

### Step 4: Set Up Backend API

Update the API endpoints in `src/services/faceRecognitionApi.ts` to point to your actual backend.

## üìÅ Files Created/Modified

### New Files:
- `src/FaceScanner.tsx` - Main face recognition component
- `src/utils/imageProcessing.ts` - Image processing utilities
- `src/services/faceRecognitionApi.ts` - API service for face recognition
- `FACE_RECOGNITION_SETUP.md` - This setup guide

### Modified Files:
- `src/types.ts` - Added FaceScanner to navigation types

## üîç Current Implementation Status

### ‚úÖ Completed:
- Face detection using vision-camera-face-detector
- Camera setup with front-facing camera
- UI with face bounding box overlay
- Basic capture functionality
- Navigation integration
- API service structure

### ‚è≥ To Be Implemented:
- Image cropping and preprocessing (using react-native-skia)
- TensorFlow.js model integration
- Backend API integration
- Error handling and validation

## üõ†Ô∏è Next Steps

### 1. Image Processing Implementation

You need to implement the `cropAndPreprocessImage` function in `src/utils/imageProcessing.ts`. Here's a basic structure:

```typescript
import { Canvas, Image, Skia } from '@shopify/react-native-skia';

export const cropAndPreprocessImage = async (
  imagePath: string,
  faceBounds: Face['bounds'],
  targetSize: number = 160
): Promise<ProcessedImage> => {
  // Load image using react-native-skia
  // Crop to face bounds
  // Resize to target size
  // Normalize pixel values
  // Return processed data
};
```

### 2. TensorFlow.js Integration

1. Download a FaceNet model (e.g., from TensorFlow Hub)
2. Place it in your assets folder
3. Update the model path in `FaceScanner.tsx`
4. Implement the inference logic

### 3. Backend API Setup

Your backend should provide these endpoints:
- `POST /api/face-recognition` - Recognize a face
- `POST /api/face-registration` - Register a new face
- `PUT /api/face-update` - Update existing face
- `DELETE /api/face-delete/:userId` - Delete a face

## üß™ Testing

1. Run the app and navigate to the FaceScanner screen
2. Grant camera permissions
3. Test face detection (green bounding box should appear)
4. Test capture functionality
5. Verify console logs for debugging

## üîß Troubleshooting

### Common Issues:

1. **Camera not working**: Check permissions and device availability
2. **Face detection not working**: Ensure vision-camera-face-detector is properly installed
3. **TensorFlow.js errors**: Check model file path and format
4. **Image processing errors**: Verify react-native-skia installation

### Debug Tips:

- Check console logs for detailed error messages
- Verify all dependencies are properly installed
- Test on both iOS and Android devices
- Ensure camera permissions are granted

## üìö Additional Resources

- [react-native-vision-camera Documentation](https://mrousavy.com/react-native-vision-camera/)
- [vision-camera-face-detector](https://github.com/mrousavy/vision-camera-face-detector)
- [@tensorflow/tfjs-react-native](https://github.com/tensorflow/tfjs/tree/master/tfjs-react-native)
- [react-native-skia Documentation](https://shopify.github.io/react-native-skia/)

## üéØ Example Usage

```typescript
// Navigate to face scanner
navigation.navigate('FaceScanner');

// The component will handle:
// - Camera permissions
// - Face detection
// - Image capture
// - Processing and API calls
```

## üìù Notes

- The face detection runs at 5 FPS to save battery
- The component uses the front-facing camera by default
- Face embeddings are 128-dimensional vectors
- Similarity threshold is typically 0.7 for FaceNet models
- Image processing should normalize to [0, 1] or [-1, 1] range

## üîí Security Considerations

- Store face embeddings securely on your backend
- Implement proper authentication for API calls
- Consider GDPR compliance for face data storage
- Use HTTPS for all API communications
- Implement rate limiting for face recognition requests
</file>

<file path="IMPLEMENTATION_SUMMARY.md">
# Face Recognition Implementation Summary

## ‚úÖ What Has Been Implemented

### 1. Core Components Created
- **`src/FaceScanner.tsx`** - Main face recognition component with:
  - Front-facing camera integration using `react-native-vision-camera`
  - Real-time face detection using `vision-camera-face-detector`
  - Face bounding box overlay
  - Capture button with loading states
  - Permission handling
  - Navigation integration

### 2. Utility Functions
- **`src/utils/imageProcessing.ts`** - Image processing utilities with:
  - Placeholder for image cropping and preprocessing
  - Face similarity calculation functions
  - TensorFlow.js data preparation functions

### 3. API Services
- **`src/services/faceRecognitionApi.ts`** - Backend API integration with:
  - Face recognition endpoint
  - Face registration endpoint
  - Face update endpoint
  - Face deletion endpoint
  - Error handling and response types

### 4. Navigation Integration
- Added `FaceScanner` to navigation types in `src/types.ts`
- Added FaceScanner screen to main navigation in `App.tsx`
- Added face recognition button to Dashboard

### 5. Dependencies Installed
- ‚úÖ `vision-camera-face-detector` - Face detection plugin
- ‚úÖ `@shopify/react-native-skia` - Graphics library for image processing
- ‚úÖ `@tensorflow/tfjs-react-native` - TensorFlow.js for React Native

## üîß Current Status

### Working Features:
1. **Camera Access** - Front-facing camera opens and displays live feed
2. **Face Detection** - Real-time face detection with bounding boxes
3. **UI/UX** - Professional interface with loading states and error handling
4. **Navigation** - Seamless integration with existing app navigation
5. **Permissions** - Proper camera permission handling

### Placeholder Features (Need Implementation):
1. **Image Processing** - Cropping and preprocessing captured images
2. **TensorFlow.js Integration** - Loading and running FaceNet model
3. **Backend API** - Connecting to your actual backend endpoints
4. **Error Handling** - Advanced error handling and validation

## üöÄ Next Steps to Complete Implementation

### Step 1: Implement Image Processing
Update `src/utils/imageProcessing.ts` to use react-native-skia for image cropping:

```typescript
import { Canvas, Image, Skia } from '@shopify/react-native-skia';

export const cropAndPreprocessImage = async (
  imagePath: string,
  faceBounds: Face['bounds'],
  targetSize: number = 160
): Promise<ProcessedImage> => {
  // Implementation using react-native-skia
  // 1. Load image from imagePath
  // 2. Crop to face bounds with padding
  // 3. Resize to targetSize x targetSize
  // 4. Normalize pixel values
  // 5. Return processed data
};
```

### Step 2: Add TensorFlow.js Model
1. Download a FaceNet model (`.json` and `.bin` files)
2. Place in your assets folder
3. Update `FaceScanner.tsx` to load and use the model:

```typescript
import * as tf from '@tensorflow/tfjs';
import '@tensorflow/tfjs-react-native';

// Initialize TensorFlow.js
await tf.ready();

// Load your model
const model = await tf.loadLayersModel('path/to/your/model.json');

// Run inference
const embedding = await model.predict(processedImage);
```

### Step 3: Connect to Backend
Update API endpoints in `src/services/faceRecognitionApi.ts`:

```typescript
// Replace with your actual backend URL
const API_BASE_URL = 'https://your-backend.com/api';

// Update all fetch calls to use your endpoints
```

### Step 4: Test and Debug
1. Test face detection on different devices
2. Verify image processing pipeline
3. Test TensorFlow.js model inference
4. Validate API integration
5. Test error scenarios

## üì± How to Use

### From Dashboard:
1. Tap the "üë§ Face Recognition" button
2. Grant camera permissions when prompted
3. Position face in the frame (green bounding box will appear)
4. Tap "Recognize Face" to process
5. View results or error messages

### Navigation:
```typescript
// Navigate to face scanner
navigation.navigate('FaceScanner');
```

## üîç Testing Checklist

- [ ] Camera permissions work correctly
- [ ] Face detection shows bounding boxes
- [ ] Capture button responds to face detection
- [ ] Loading states display properly
- [ ] Error handling works for edge cases
- [ ] Navigation back to Dashboard works
- [ ] Console logs show processing steps

## üõ†Ô∏è Development Tips

### Debugging:
- Check console logs for detailed processing information
- Use React Native Debugger for state inspection
- Test on both iOS and Android devices
- Verify all dependencies are properly linked

### Performance:
- Face detection runs at 5 FPS to save battery
- Image processing should be optimized for speed
- Consider caching processed results
- Monitor memory usage with large images

### Security:
- Implement proper authentication for API calls
- Secure storage of face embeddings
- Consider GDPR compliance
- Use HTTPS for all communications

## üìö Resources

- [Face Recognition Setup Guide](./FACE_RECOGNITION_SETUP.md)
- [react-native-vision-camera Documentation](https://mrousavy.com/react-native-vision-camera/)
- [vision-camera-face-detector](https://github.com/mrousavy/vision-camera-face-detector)
- [@tensorflow/tfjs-react-native](https://github.com/tensorflow/tfjs/tree/master/tfjs-react-native)
- [react-native-skia Documentation](https://shopify.github.io/react-native-skia/)

## üéØ Success Metrics

When fully implemented, you should be able to:
1. Detect faces in real-time with high accuracy
2. Process face images to generate embeddings
3. Compare embeddings for face recognition
4. Integrate with your backend for user identification
5. Handle errors gracefully with user-friendly messages

## üîÑ Future Enhancements

- Face liveness detection
- Multiple face detection and selection
- Face quality assessment
- Offline face recognition
- Face emotion detection
- Integration with existing student database
</file>

<file path="QR_SCANNER_TESTING.md">
# QR Scanner Testing Guide

## üß™ **Testing the QR Scanner**

### **How the QR Scanner Works**

1. **Scan Student QR Code** ‚Üí Extract student data
2. **Parse QR Data** ‚Üí Convert to Student object
3. **Fetch Details** ‚Üí Call mock API with student ID
4. **Navigate to Payment** ‚Üí Pass student data to PaymentScreen

### **QR Code Format**

The scanner expects QR codes containing student data in JSON format:

```json
{
  "id": "STU001",
  "name": "John Smith",
  "email": "john.smith@university.edu",
  "phone": "+1-555-0123",
  "department": "Computer Science",
  "balance": 1250.00,
  "studentId": "STU001",
  "semester": "Fall 2024",
  "year": "2024"
}
```

### **Testing Methods**

#### **Method 1: Demo Mode (Quick Test)**
1. Open the merchant app
2. Tap "üì± Scan Student QR Code"
3. Tap "Demo: Scan Test QR"
4. Verify navigation to PaymentScreen
5. Check student details are correct

#### **Method 2: Manual QR Input (Real Testing)**
1. Open the merchant app
2. Tap "üì± Scan Student QR Code"
3. Tap "Manual QR Input"
4. Paste the JSON data from your QR code
5. Tap "Process QR Data"
6. Verify the complete flow works

#### **Method 3: Generate Real QR Codes**
1. Use any online QR code generator
2. Generate QR codes with the JSON data below
3. Use "Manual QR Input" to paste the JSON content
4. Test the complete scanning flow

### **Test QR Code Data**

#### **Student 1:**
```json
{"id":"STU001","name":"John Smith","email":"john.smith@university.edu","phone":"+1-555-0123","department":"Computer Science","balance":1250.00,"studentId":"STU001","semester":"Fall 2024","year":"2024"}
```

#### **Student 2:**
```json
{"id":"STU002","name":"Sarah Johnson","email":"sarah.johnson@university.edu","phone":"+1-555-0124","department":"Business Administration","balance":850.50,"studentId":"STU002","semester":"Fall 2024","year":"2024"}
```

#### **Student 3:**
```json
{"id":"STU003","name":"Michael Chen","email":"michael.chen@university.edu","phone":"+1-555-0125","department":"Engineering","balance":2100.75,"studentId":"STU003","semester":"Fall 2024","year":"2024"}
```

### **Step-by-Step Real QR Testing**

#### **Step 1: Generate QR Code**
1. Go to any online QR code generator (e.g., qr-code-generator.com)
2. Copy one of the JSON data samples above
3. Generate the QR code
4. Save the QR code image

#### **Step 2: Extract QR Data**
1. Use any QR code scanner app on your phone
2. Scan the generated QR code
3. Copy the extracted JSON data

#### **Step 3: Test in Merchant App**
1. Open the merchant app
2. Navigate to QR Scanner
3. Tap "Manual QR Input"
4. Paste the copied JSON data
5. Tap "Process QR Data"
6. Verify student details appear
7. Test navigation to PaymentScreen
8. Test payment processing

### **Expected Behavior**

‚úÖ **Valid QR Code:**
- Scanner processes QR data
- Parses student information
- Fetches additional details from API
- Navigates to PaymentScreen
- Shows correct student information

‚ùå **Invalid QR Code:**
- Shows error message
- Allows retry
- Doesn't navigate to PaymentScreen

### **Test Cases**

1. **Valid JSON QR Code** ‚Üí Should work perfectly
2. **Student ID Only** ‚Üí Should fetch details from API
3. **Empty QR Code** ‚Üí Should show error
4. **Invalid JSON** ‚Üí Should show error
5. **Unknown Student ID** ‚Üí Should show error

### **Debug Information**

The app logs these details to console:
- `QR Code Scanned: [data]`
- `Parsed Student Data: [object]`
- `Fetched Student Details: [object]`

### **Quick Test with Manual Input**

1. **Open QR Scanner**
2. **Tap "Manual QR Input"**
3. **Paste this test data:**
   ```json
   {"id":"STU001","name":"John Smith","email":"john.smith@university.edu","phone":"+1-555-0123","department":"Computer Science","balance":1250.00,"studentId":"STU001","semester":"Fall 2024","year":"2024"}
   ```
4. **Tap "Process QR Data"**
5. **Verify navigation to PaymentScreen**
6. **Check student details are correct**
7. **Test payment processing**

### **Real QR Code Testing Workflow**

1. **Generate QR Code** ‚Üí Use online generator with JSON data
2. **Extract Data** ‚Üí Scan with any QR app to get JSON
3. **Manual Input** ‚Üí Paste JSON in merchant app
4. **Process Data** ‚Üí Verify parsing and API calls
5. **Navigate to Payment** ‚Üí Test complete flow
6. **Process Payment** ‚Üí Verify payment handling

This approach allows you to test real QR code functionality without complex camera integration issues!
</file>

<file path="REAL_TIME_FACE_DETECTION_GUIDE.md">
# Real-Time Face Detection Implementation Guide

## üéØ **Current Status**
Your app now has:
- ‚úÖ Camera integration with react-native-vision-camera
- ‚úÖ Image processing with react-native-skia
- ‚úÖ TensorFlow.js framework ready
- ‚úÖ Professional UI/UX
- ‚è≥ **Real-time face detection (needs implementation)**

## üöÄ **Implementation Options**

### **Option 1: Google ML Kit Face Detection (Recommended)**

This is the most reliable and easiest to implement.

#### Step 1: Install ML Kit
```bash
npm install @react-native-ml-kit/face-detection
```

#### Step 2: Update FaceScanner.tsx
```typescript
import FaceDetection from '@react-native-ml-kit/face-detection';

// Add this function to your component
const detectFacesInImage = async (imagePath: string) => {
  try {
    const faces = await FaceDetection.detect(imagePath);
    if (faces.length > 0) {
      const face = faces[0];
      const bounds = {
        x: face.boundingBox.left,
        y: face.boundingBox.top,
        width: face.boundingBox.right - face.boundingBox.left,
        height: face.boundingBox.bottom - face.boundingBox.top,
      };
      setFaces([{ bounds }]);
      setIsFaceDetected(true);
      return true;
    }
    return false;
  } catch (error) {
    console.error('Face detection error:', error);
    return false;
  }
};

// Update handleCaptureAndProcess
const handleCaptureAndProcess = async () => {
  if (!camera.current) {
    Alert.alert("Error", "Camera is not available.");
    return;
  }

  setIsLoading(true);

  try {
    // Step 1: Take snapshot
    const snapshot = await camera.current.takeSnapshot({ 
      quality: 85, 
      skipMetadata: true 
    });
    
    // Step 2: Detect faces in the snapshot
    const faceDetected = await detectFacesInImage(snapshot.path);
    
    if (!faceDetected) {
      Alert.alert("No Face Detected", "Please make sure your face is visible.");
      return;
    }

    // Step 3: Process the detected face
    const processedImageData = await cropAndPreprocessImage(snapshot.path, faces[0].bounds);
    
    // Step 4: Run TensorFlow.js inference
    if (model) {
      const imageTensor = tf.tensor(processedImageData, [1, 160, 160, 3]);
      const prediction = model.predict(imageTensor) as tf.Tensor;
      const embedding = await prediction.data();
      tf.dispose([imageTensor, prediction]);
      
      console.log("Embedding generated:", Array.from(embedding).slice(0, 5));
    }

    Alert.alert("Success", "Face processed successfully!");
    
  } catch (error) {
    console.error("Error:", error);
    Alert.alert("Error", "Processing failed.");
  } finally {
    setIsLoading(false);
  }
};
```

### **Option 2: TensorFlow.js Face Detection Model**

For more control and offline capability.

#### Step 1: Download Face Detection Model
Download a TensorFlow.js face detection model (like BlazeFace) and place it in your assets folder.

#### Step 2: Implement Face Detection
```typescript
// Load face detection model
const [faceDetectionModel, setFaceDetectionModel] = useState<tf.GraphModel | null>(null);

useEffect(() => {
  const loadModels = async () => {
    await tf.ready();
    
    // Load face detection model
    const faceDetectionModelJson = require('../assets/face-detection/model.json');
    const faceDetectionModelWeights = require('../assets/face-detection/weights.bin');
    const faceModel = await tf.loadGraphModel(bundleResourceIO(faceDetectionModelJson, faceDetectionModelWeights));
    setFaceDetectionModel(faceModel);
    
    // Load face recognition model (FaceNet)
    // ... your existing model loading code
  };
  loadModels();
}, []);

// Face detection function
const detectFacesWithTensorFlow = async (imageData: Float32Array) => {
  if (!faceDetectionModel) return false;
  
  const inputTensor = tf.tensor(imageData, [1, 256, 256, 3]);
  const predictions = faceDetectionModel.predict(inputTensor) as tf.Tensor;
  const results = await predictions.data();
  
  // Process detection results
  // This depends on your specific model output format
  
  tf.dispose([inputTensor, predictions]);
  return true;
};
```

### **Option 3: Custom Face Detection with OpenCV.js**

For advanced users who want full control.

#### Step 1: Install OpenCV.js
```bash
npm install opencv-js
```

#### Step 2: Implement Custom Detection
```typescript
import cv from 'opencv-js';

const detectFacesWithOpenCV = async (imagePath: string) => {
  // Load image with OpenCV
  const image = await cv.imread(imagePath);
  
  // Convert to grayscale
  const gray = new cv.Mat();
  cv.cvtColor(image, gray, cv.COLOR_RGBA2GRAY);
  
  // Load Haar cascade classifier
  const classifier = new cv.CascadeClassifier();
  classifier.load('haarcascade_frontalface_default.xml');
  
  // Detect faces
  const faces = new cv.RectVector();
  classifier.detectMultiScale(gray, faces);
  
  // Process results
  const detectedFaces = [];
  for (let i = 0; i < faces.size(); i++) {
    const face = faces.get(i);
    detectedFaces.push({
      bounds: {
        x: face.x,
        y: face.y,
        width: face.width,
        height: face.height,
      }
    });
  }
  
  // Clean up
  image.delete();
  gray.delete();
  faces.delete();
  
  return detectedFaces;
};
```

## üîß **Recommended Implementation Steps**

### **Phase 1: Quick Implementation (Option 1)**
1. Install Google ML Kit
2. Implement face detection in snapshot
3. Test with your existing image processing
4. Connect to your backend API

### **Phase 2: Real-Time Detection**
1. Implement frame-by-frame processing
2. Add face tracking
3. Optimize performance
4. Add face quality assessment

### **Phase 3: Advanced Features**
1. Multiple face detection
2. Face liveness detection
3. Face emotion recognition
4. Offline processing

## üì± **Testing Your Implementation**

### **Test Checklist:**
- [ ] Camera opens and shows live feed
- [ ] Face detection works on snapshots
- [ ] Image processing completes successfully
- [ ] TensorFlow.js model loads (when implemented)
- [ ] Embeddings are generated correctly
- [ ] Backend API integration works
- [ ] Error handling works properly
- [ ] Performance is acceptable

### **Performance Targets:**
- Face detection: < 500ms
- Image processing: < 1 second
- Model inference: < 2 seconds
- Total processing: < 4 seconds

## üõ†Ô∏è **Troubleshooting**

### **Common Issues:**
1. **Face detection not working**: Check model loading and image format
2. **Slow performance**: Optimize image size and processing pipeline
3. **Memory issues**: Implement proper cleanup with tf.dispose()
4. **Camera permissions**: Ensure proper permission handling

### **Debug Tips:**
- Use console.log to track processing steps
- Test with different face positions and lighting
- Monitor memory usage during processing
- Test on different device types

## üéØ **Next Steps**

1. **Choose your implementation option** (recommend Option 1)
2. **Install the required dependencies**
3. **Implement face detection logic**
4. **Test with your current setup**
5. **Add real-time processing if needed**
6. **Connect to your backend API**

Your current implementation provides a solid foundation. The face detection is the final piece to make it fully functional!
</file>

<file path="src/FaceScanner.tsx">
import React, { useState, useRef, useEffect } from 'react';
import { View, Text, StyleSheet, TouchableOpacity, Alert, ActivityIndicator } from 'react-native';
import { Camera, useCameraDevice, useCameraPermission } from 'react-native-vision-camera';
import { StackNavigationProp } from '@react-navigation/stack';
import { RootStackParamList } from './types';

// Face recognition imports (simplified for now)
// import * as tf from '@tensorflow/tfjs';
// import '@tensorflow/tfjs-react-native';
// import { cropAndPreprocessImage } from './utils/imageProcessing';

// Face detection interface
interface Face {
  bounds: {
    x: number;
    y: number;
    width: number;
    height: number;
  };
}

type FaceScannerNavigationProp = StackNavigationProp<RootStackParamList, 'FaceScanner'>;

interface Props {
  navigation: FaceScannerNavigationProp;
}

// --- Main Component ---
const FaceScanner: React.FC<Props> = ({ navigation }) => {
  const { hasPermission, requestPermission } = useCameraPermission();
  const device = useCameraDevice('front');
  const camera = useRef<Camera>(null);

  const [faces, setFaces] = useState<Face[]>([]);
  const [isLoading, setIsLoading] = useState(false);
  const [model, setModel] = useState<any>(null);
  const [isFaceDetected, setIsFaceDetected] = useState(false);

  // Load model when component mounts (simplified for now)
  useEffect(() => {
    const loadModel = async () => {
      try {
        // await tf.ready();
        console.log('Model loading placeholder - TensorFlow.js will be implemented later');
        
        // For now, we'll use a placeholder model loading
        // In production, you would load your actual FaceNet model here
        // const modelJson = require('../assets/model/model.json');
        // const modelWeights = require('../assets/model/weights.bin');
        // const loadedModel = await tf.loadGraphModel(bundleResourceIO(modelJson, modelWeights));
        // setModel(loadedModel);
        
        console.log("Model loading placeholder - implement with actual FaceNet model");
      } catch (error) {
        console.error('Error loading model:', error);
      }
    };
    loadModel();
  }, []);

  // Simulate face detection for now (will be replaced with real detection)
  const detectFace = () => {
    // Simulate face detection in the center of the screen
    const centerFace: Face = {
      bounds: {
        x: 100,
        y: 200,
        width: 150,
        height: 150,
      }
    };
    setFaces([centerFace]);
    setIsFaceDetected(true);
    console.log('Face detection simulated:', centerFace.bounds);
  };

  // --- Main Function to Handle Capture and Processing ---
  const handleCaptureAndProcess = async () => {
    if (!camera.current) {
      Alert.alert("Error", "Camera is not available.");
      return;
    }
    if (!isFaceDetected) {
      Alert.alert("No Face Detected", "Please tap 'Detect Face' first to simulate face detection.");
      return;
    }

    setIsLoading(true);

    try {
      // Step 1: Take a high-resolution snapshot
      const snapshot = await camera.current.takeSnapshot({ 
        quality: 85, 
        skipMetadata: true 
      });
      console.log(`Snapshot taken at: ${snapshot.path}`);

      // Step 2: Image processing placeholder
      console.log("Processing image with face bounds:", faces[0].bounds);
      // const processedImageData = await cropAndPreprocessImage(snapshot.path, faces[0].bounds);
      console.log("Image processing placeholder - will be implemented with react-native-skia");

      // Step 3: TensorFlow.js inference placeholder
      if (model) {
        // Create a Tensor for the model
        // const imageTensor = tf.tensor(processedImageData, [1, 160, 160, 3]);
        // const prediction = model.predict(imageTensor) as tf.Tensor;
        // const embedding = await prediction.data();
        // tf.dispose([imageTensor, prediction]);
        
        console.log("Model inference placeholder - will be implemented with TensorFlow.js");
      } else {
        // Placeholder embedding for testing
        const embedding = new Float32Array(128).fill(0.1);
        console.log("Using placeholder embedding (model not loaded)");
      }

      // Step 4: Send the embedding to your backend
      console.log("Ready to send embedding to backend API...");
      /*
      const response = await fetch('https://your-backend.com/api/face-recognition', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ embedding: Array.from(embedding) }),
      });
      const result = await response.json();
      if (result.success) {
        Alert.alert("Success", `User recognized: ${result.userName}`);
      } else {
        Alert.alert("Failure", "User not found in database.");
      }
      */
      Alert.alert("Process Complete", "Face processed successfully! Embedding ready for backend.");

    } catch (error) {
      console.error("An error occurred:", error);
      Alert.alert("Error", "An unexpected error occurred during the process.");
    } finally {
      setIsLoading(false);
    }
  };

  // --- UI Rendering ---
  if (!hasPermission) {
    return (
      <View style={styles.permissionContainer}>
        <Text style={styles.permissionText}>Camera Permission Required</Text>
        <TouchableOpacity style={styles.permissionButton} onPress={requestPermission}>
          <Text style={styles.permissionButtonText}>Grant Permission</Text>
        </TouchableOpacity>
      </View>
    );
  }

  if (!device) {
    return (
      <View style={styles.permissionContainer}>
        <Text style={styles.permissionText}>No Front Camera Found</Text>
      </View>
    );
  }

  return (
    <View style={styles.container}>
      <Camera
        ref={camera}
        style={StyleSheet.absoluteFill}
        device={device}
        isActive={true}
        photo={true}
      />

      {/* Overlay to draw face bounding boxes */}
      {faces.map((face, i) => (
        <View
          key={i}
          style={[
            styles.faceBounds,
            {
              top: face.bounds.y,
              left: face.bounds.x,
              width: face.bounds.width,
              height: face.bounds.height,
            },
          ]}
        />
      ))}

      {/* Header with back button */}
      <View style={styles.header}>
        <TouchableOpacity onPress={() => navigation.goBack()} style={styles.cancelButton}>
          <Text style={styles.cancelButtonText}>‚úï Cancel</Text>
        </TouchableOpacity>
      </View>

      {/* Center content */}
      <View style={styles.centerContent}>
        <Text style={styles.overlayText}>Face Recognition</Text>
        <Text style={styles.subText}>
          {isFaceDetected ? 'Face detected! Press capture to recognize.' : 'Position your face in the frame and tap "Detect Face"'}
        </Text>
        
        <View style={styles.faceFrame}>
          <View style={[styles.corner, styles.topLeft]} />
          <View style={[styles.corner, styles.topRight]} />
          <View style={[styles.corner, styles.bottomLeft]} />
          <View style={[styles.corner, styles.bottomRight]} />
        </View>
      </View>

      {/* Bottom controls */}
      <View style={styles.bottomContainer}>
        {!isFaceDetected && (
          <TouchableOpacity
            style={styles.detectButton}
            onPress={detectFace}
          >
            <Text style={styles.buttonText}>Detect Face</Text>
          </TouchableOpacity>
        )}
        
        {isFaceDetected && (
          <TouchableOpacity
            style={[styles.captureButton, isLoading && styles.disabledButton]}
            onPress={handleCaptureAndProcess}
            disabled={isLoading}
          >
            {isLoading ? (
              <ActivityIndicator color="#fff" />
            ) : (
              <Text style={styles.buttonText}>Recognize Face</Text>
            )}
          </TouchableOpacity>
        )}
      </View>
    </View>
  );
};

// --- Styles ---
const styles = StyleSheet.create({
  container: { 
    flex: 1, 
    backgroundColor: '#000' 
  },
  header: { 
    position: 'absolute', 
    top: 50, 
    left: 20, 
    zIndex: 10 
  },
  cancelButton: { 
    backgroundColor: 'rgba(0,0,0,0.6)', 
    paddingHorizontal: 15, 
    paddingVertical: 8, 
    borderRadius: 20 
  },
  cancelButtonText: { 
    color: '#fff', 
    fontSize: 14, 
    fontWeight: 'bold' 
  },
  centerContent: { 
    position: 'absolute', 
    top: 0, 
    left: 0, 
    right: 0, 
    bottom: 0, 
    alignItems: 'center', 
    justifyContent: 'center' 
  },
  overlayText: { 
    color: '#fff', 
    fontSize: 24, 
    fontWeight: 'bold', 
    textAlign: 'center', 
    backgroundColor: 'rgba(0,0,0,0.7)', 
    paddingHorizontal: 20, 
    paddingVertical: 10, 
    borderRadius: 10, 
    marginBottom: 10 
  },
  subText: { 
    color: '#fff', 
    fontSize: 16, 
    textAlign: 'center', 
    backgroundColor: 'rgba(0,0,0,0.5)', 
    paddingHorizontal: 15, 
    paddingVertical: 5, 
    borderRadius: 8, 
    marginBottom: 30 
  },
  faceFrame: { 
    width: 250, 
    height: 250, 
    borderWidth: 2, 
    borderColor: '#fff', 
    backgroundColor: 'transparent', 
    position: 'relative' 
  },
  corner: { 
    position: 'absolute', 
    width: 30, 
    height: 30, 
    borderColor: '#00ff00', 
    borderWidth: 4 
  },
  topLeft: { 
    top: -4, 
    left: -4, 
    borderRightWidth: 0, 
    borderBottomWidth: 0 
  },
  topRight: { 
    top: -4, 
    right: -4, 
    borderLeftWidth: 0, 
    borderBottomWidth: 0 
  },
  bottomLeft: { 
    bottom: -4, 
    left: -4, 
    borderRightWidth: 0, 
    borderTopWidth: 0 
  },
  bottomRight: { 
    bottom: -4, 
    right: -4, 
    borderLeftWidth: 0, 
    borderTopWidth: 0 
  },
  bottomContainer: { 
    position: 'absolute', 
    bottom: 40, 
    alignSelf: 'center' 
  },
  detectButton: { 
    backgroundColor: '#27ae60', 
    padding: 20, 
    borderRadius: 50,
    minWidth: 150,
    alignItems: 'center'
  },
  captureButton: { 
    backgroundColor: '#3498db', 
    padding: 20, 
    borderRadius: 50,
    minWidth: 150,
    alignItems: 'center'
  },
  disabledButton: { 
    backgroundColor: '#7f8c8d' 
  },
  buttonText: { 
    color: 'white', 
    fontSize: 18, 
    fontWeight: 'bold' 
  },
  faceBounds: { 
    position: 'absolute', 
    borderWidth: 2, 
    borderColor: '#00ff00',
    backgroundColor: 'transparent'
  },
  permissionContainer: { 
    flex: 1, 
    justifyContent: 'center', 
    alignItems: 'center', 
    padding: 20, 
    backgroundColor: '#000' 
  },
  permissionText: { 
    fontSize: 22, 
    fontWeight: 'bold', 
    color: '#fff', 
    textAlign: 'center', 
    marginBottom: 20 
  },
  permissionButton: { 
    backgroundColor: '#3498db', 
    paddingHorizontal: 30, 
    paddingVertical: 15, 
    borderRadius: 25 
  },
  permissionButtonText: { 
    color: '#fff', 
    fontSize: 16, 
    fontWeight: 'bold' 
  },
});

export default FaceScanner;
</file>

<file path="src/QRCodeGenerator.tsx">
import React, { useState } from 'react';
import { View, Text, StyleSheet, TextInput, TouchableOpacity, ScrollView, Alert } from 'react-native';

interface PersonData {
  id: string;
  name: string;
  email: string;
  phone: string;
  department: string;
  position: string;
}

const QRCodeGenerator = (): React.JSX.Element => {
  const [personData, setPersonData] = useState<PersonData>({
    id: 'EMP001',
    name: 'John Doe',
    email: 'john.doe@company.com',
    phone: '+1-555-0123',
    department: 'Engineering',
    position: 'Senior Developer',
  });

  const [generatedData, setGeneratedData] = useState('');

  const generateQRData = () => {
    const jsonData = JSON.stringify(personData);
    setGeneratedData(jsonData);
    Alert.alert('QR Data Generated', `Use this data to create a QR code:\n\n${jsonData}`);
  };

  const generateCSVData = () => {
    const csvData = `${personData.id},${personData.name},${personData.email},${personData.phone},${personData.department},${personData.position}`;
    setGeneratedData(csvData);
    Alert.alert('CSV Data Generated', `Use this data to create a QR code:\n\n${csvData}`);
  };

  const updateField = (field: keyof PersonData, value: string) => {
    setPersonData(prev => ({ ...prev, [field]: value }));
  };

  return (
    <ScrollView style={styles.container}>
      <Text style={styles.title}>QR Code Data Generator</Text>
      <Text style={styles.subtitle}>Generate test data for QR scanner</Text>

      <View style={styles.inputContainer}>
        <Text style={styles.label}>ID:</Text>
        <TextInput
          style={styles.input}
          value={personData.id}
          onChangeText={(text) => updateField('id', text)}
          placeholder="Enter ID"
        />
      </View>

      <View style={styles.inputContainer}>
        <Text style={styles.label}>Name:</Text>
        <TextInput
          style={styles.input}
          value={personData.name}
          onChangeText={(text) => updateField('name', text)}
          placeholder="Enter Name"
        />
      </View>

      <View style={styles.inputContainer}>
        <Text style={styles.label}>Email:</Text>
        <TextInput
          style={styles.input}
          value={personData.email}
          onChangeText={(text) => updateField('email', text)}
          placeholder="Enter Email"
          keyboardType="email-address"
        />
      </View>

      <View style={styles.inputContainer}>
        <Text style={styles.label}>Phone:</Text>
        <TextInput
          style={styles.input}
          value={personData.phone}
          onChangeText={(text) => updateField('phone', text)}
          placeholder="Enter Phone"
          keyboardType="phone-pad"
        />
      </View>

      <View style={styles.inputContainer}>
        <Text style={styles.label}>Department:</Text>
        <TextInput
          style={styles.input}
          value={personData.department}
          onChangeText={(text) => updateField('department', text)}
          placeholder="Enter Department"
        />
      </View>

      <View style={styles.inputContainer}>
        <Text style={styles.label}>Position:</Text>
        <TextInput
          style={styles.input}
          value={personData.position}
          onChangeText={(text) => updateField('position', text)}
          placeholder="Enter Position"
        />
      </View>

      <View style={styles.buttonContainer}>
        <TouchableOpacity style={styles.button} onPress={generateQRData}>
          <Text style={styles.buttonText}>Generate JSON Data</Text>
        </TouchableOpacity>
        
        <TouchableOpacity style={styles.button} onPress={generateCSVData}>
          <Text style={styles.buttonText}>Generate CSV Data</Text>
        </TouchableOpacity>
      </View>

      {generatedData && (
        <View style={styles.resultContainer}>
          <Text style={styles.resultTitle}>Generated Data:</Text>
          <Text style={styles.resultText}>{generatedData}</Text>
          <Text style={styles.instruction}>
            Copy this data and use an online QR code generator to create a QR code for testing.
          </Text>
        </View>
      )}
    </ScrollView>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    padding: 20,
    backgroundColor: '#f5f5f5',
  },
  title: {
    fontSize: 24,
    fontWeight: 'bold',
    textAlign: 'center',
    marginBottom: 10,
    color: '#333',
  },
  subtitle: {
    fontSize: 16,
    textAlign: 'center',
    marginBottom: 30,
    color: '#666',
  },
  inputContainer: {
    marginBottom: 15,
  },
  label: {
    fontSize: 16,
    fontWeight: 'bold',
    marginBottom: 5,
    color: '#333',
  },
  input: {
    borderWidth: 1,
    borderColor: '#ddd',
    borderRadius: 8,
    padding: 12,
    fontSize: 16,
    backgroundColor: '#fff',
  },
  buttonContainer: {
    marginTop: 20,
    marginBottom: 20,
  },
  button: {
    backgroundColor: '#007AFF',
    padding: 15,
    borderRadius: 8,
    marginBottom: 10,
    alignItems: 'center',
  },
  buttonText: {
    color: '#fff',
    fontSize: 16,
    fontWeight: 'bold',
  },
  resultContainer: {
    backgroundColor: '#fff',
    padding: 15,
    borderRadius: 8,
    borderWidth: 1,
    borderColor: '#ddd',
  },
  resultTitle: {
    fontSize: 18,
    fontWeight: 'bold',
    marginBottom: 10,
    color: '#333',
  },
  resultText: {
    fontSize: 14,
    color: '#666',
    backgroundColor: '#f8f9fa',
    padding: 10,
    borderRadius: 5,
    marginBottom: 10,
  },
  instruction: {
    fontSize: 14,
    color: '#666',
    fontStyle: 'italic',
  },
});

export default QRCodeGenerator;
</file>

<file path="src/QrScanner.tsx">
import React, { useState, useEffect } from 'react';
import { View, Text, StyleSheet, Alert, TouchableOpacity, ActivityIndicator } from 'react-native';
import { Camera, useCameraDevice, useCameraPermission, useCodeScanner } from 'react-native-vision-camera';
import { StackNavigationProp } from '@react-navigation/stack';
import { RootStackParamList, Student } from './types';
import { fetchStudentDetails } from './services/mockApi';

type QrScannerNavigationProp = StackNavigationProp<RootStackParamList, 'QrScanner'>;

interface Props {
  navigation: QrScannerNavigationProp;
}

const QrScanner: React.FC<Props> = ({ navigation }) => {
  const { hasPermission, requestPermission } = useCameraPermission();
  const [isScannerActive, setIsScannerActive] = useState(true);
  const [isLoading, setIsLoading] = useState(false);
  const [lastScannedCode, setLastScannedCode] = useState('');
  const device = useCameraDevice('back');

  const codeScanner = useCodeScanner({
    codeTypes: ['qr'],
    onCodeScanned: (codes) => {
      if (isScannerActive && !isLoading && codes.length > 0 && codes[0].value) {
        const scannedValue = codes[0].value;
        if (scannedValue && scannedValue !== lastScannedCode) {
          console.log(`Scanned QR Code: ${scannedValue}`);
          setIsScannerActive(false); // Pause the scanner
          handleQRCodeScanned(scannedValue); // Process the code
        }
      }
    }
  });

  useEffect(() => {
    if (!hasPermission) {
      requestPermission();
    }
  }, [hasPermission, requestPermission]);

  const parseQRData = (data: string): Student | null => {
    try {
      const parsed = JSON.parse(data);
      if (parsed.studentId) {
        return {
          id: parsed.id || parsed.studentId, name: parsed.name || 'N/A',
          email: parsed.email || 'N/A', phone: parsed.phone || 'N/A',
          department: parsed.department || 'N/A', balance: parsed.balance || 0,
          studentId: parsed.studentId, semester: parsed.semester || 'N/A',
          year: parsed.year || 'N/A',
        };
      }
    } catch (e) {
      if (data.trim()) {
        return {
          id: data.trim(), name: 'Unknown', email: 'N/A', phone: 'N/A',
          department: 'N/A', balance: 0, studentId: data.trim(),
          semester: 'N/A', year: 'N/A',
        };
      }
    }
    return null;
  };

  const handleQRCodeScanned = async (data: string) => {
    if (!data || data.trim() === '') {
      Alert.alert('Invalid QR Code', 'The scanned QR code is empty.');
      handleScanAgain();
      return;
    }
    
    setIsLoading(true);
    setLastScannedCode(data);

    try {
      const studentData = parseQRData(data);
      if (!studentData) {
        Alert.alert('Invalid QR Code', 'The QR code format is incorrect.', [{ text: 'OK', onPress: handleScanAgain }]);
        return;
      }

      const fetchedStudent = await fetchStudentDetails(studentData.studentId);
      navigation.navigate('PaymentScreen', { student: fetchedStudent });

    } catch (error) {
      Alert.alert('Processing Error', 'Student with ID not found. Please try a different QR code.', [{ text: 'Scan Again', onPress: handleScanAgain }]);
    } finally {
      setIsLoading(false);
    }
  };

  const handleScanAgain = () => {
    setLastScannedCode('');
    setIsScannerActive(true); // Re-activate the scanner
  };
  
  if (!hasPermission) {
    return (
      <View style={styles.permissionContainer}>
        <Text style={styles.permissionText}>Camera Permission Required</Text>
        <TouchableOpacity style={styles.permissionButton} onPress={requestPermission}>
          <Text style={styles.permissionButtonText}>Grant Permission</Text>
        </TouchableOpacity>
      </View>
    );
  }

  if (!device) {
    return (
      <View style={styles.permissionContainer}>
        <Text style={styles.permissionText}>No Camera Device Found</Text>
      </View>
    );
  }

  return (
    <View style={styles.container}>
      <Camera
        style={StyleSheet.absoluteFill}
        device={device}
        isActive={isScannerActive && !isLoading}
        codeScanner={codeScanner}
        photo={false}
      />

      <View style={styles.overlay}>
        <View style={styles.header}>
          <TouchableOpacity onPress={() => navigation.goBack()} style={styles.cancelButton}>
            <Text style={styles.cancelButtonText}>‚úï Cancel</Text>
          </TouchableOpacity>
        </View>

        <View style={styles.centerContent}>
          <Text style={styles.overlayText}>Scan Student QR Code</Text>
          <Text style={styles.subText}>Point camera at the QR code</Text>
          
          <View style={styles.scanFrame}>
            <View style={[styles.corner, styles.topLeft]} />
            <View style={[styles.corner, styles.topRight]} />
            <View style={[styles.corner, styles.bottomLeft]} />
            <View style={[styles.corner, styles.bottomRight]} />
          </View>
        </View>

        <View style={styles.bottomContent}>
            {isLoading && (
                <View style={styles.loadingContainer}>
                    <ActivityIndicator size="large" color="#fff" />
                    <Text style={styles.loadingText}>Processing...</Text>
                </View>
            )}
        </View>
      </View>
    </View>
  );
};

const styles = StyleSheet.create({
  container: { flex: 1, backgroundColor: '#000' },
  overlay: { position: 'absolute', top: 0, left: 0, right: 0, bottom: 0, justifyContent: 'space-between' },
  header: { flexDirection: 'row', justifyContent: 'flex-start', paddingTop: 50, paddingHorizontal: 20 },
  cancelButton: { backgroundColor: 'rgba(0,0,0,0.6)', paddingHorizontal: 15, paddingVertical: 8, borderRadius: 20 },
  cancelButtonText: { color: '#fff', fontSize: 14, fontWeight: 'bold' },
  centerContent: { alignItems: 'center', flex: 1, justifyContent: 'center' },
  overlayText: { color: '#fff', fontSize: 24, fontWeight: 'bold', textAlign: 'center', backgroundColor: 'rgba(0,0,0,0.7)', paddingHorizontal: 20, paddingVertical: 10, borderRadius: 10, marginBottom: 10 },
  subText: { color: '#fff', fontSize: 16, textAlign: 'center', backgroundColor: 'rgba(0,0,0,0.5)', paddingHorizontal: 15, paddingVertical: 5, borderRadius: 8, marginBottom: 30 },
  scanFrame: { width: 250, height: 250, borderWidth: 2, borderColor: '#fff', backgroundColor: 'transparent', position: 'relative' },
  corner: { position: 'absolute', width: 30, height: 30, borderColor: '#00ff00', borderWidth: 4 },
  topLeft: { top: -4, left: -4, borderRightWidth: 0, borderBottomWidth: 0 },
  topRight: { top: -4, right: -4, borderLeftWidth: 0, borderBottomWidth: 0 },
  bottomLeft: { bottom: -4, left: -4, borderRightWidth: 0, borderTopWidth: 0 },
  bottomRight: { bottom: -4, right: -4, borderLeftWidth: 0, borderTopWidth: 0 },
  bottomContent: { height: 100, alignItems: 'center', padding: 20 },
  loadingContainer: { justifyContent: 'center', alignItems: 'center' },
  loadingText: { color: '#fff', fontSize: 18, marginTop: 10, textAlign: 'center' },
  permissionContainer: { flex: 1, justifyContent: 'center', alignItems: 'center', padding: 20, backgroundColor: '#000' },
  permissionText: { fontSize: 22, fontWeight: 'bold', color: '#fff', textAlign: 'center', marginBottom: 20 },
  permissionButton: { backgroundColor: '#3498db', paddingHorizontal: 30, paddingVertical: 15, borderRadius: 25 },
  permissionButtonText: { color: '#fff', fontSize: 16, fontWeight: 'bold' },
});

export default QrScanner;
</file>

<file path="src/screens/Dashboard.tsx">
import React from 'react';
import {
  View,
  Text,
  StyleSheet,
  TouchableOpacity,
  SafeAreaView,
  StatusBar,
  Alert,
} from 'react-native';
import { StackNavigationProp } from '@react-navigation/stack';
import { RootStackParamList } from '../types';

type DashboardScreenNavigationProp = StackNavigationProp<RootStackParamList, 'Dashboard'>;

interface Props {
  navigation: DashboardScreenNavigationProp;
}

const Dashboard: React.FC<Props> = ({ navigation }) => {
  return (
    <SafeAreaView style={styles.container}>
      <StatusBar barStyle="dark-content" backgroundColor="#f8f9fa" />
      
      <View style={styles.header}>
        <Text style={styles.title}>Merchant Dashboard</Text>
        <Text style={styles.subtitle}>Student Payment Portal</Text>
      </View>

      <View style={styles.content}>
        <View style={styles.card}>
          <Text style={styles.cardTitle}>Quick Actions</Text>
          
          <TouchableOpacity
            style={styles.scanButton}
            onPress={() => navigation.navigate('QrScanner')}
          >
            <Text style={styles.scanButtonText}>üì± Scan Student QR Code</Text>
            <Text style={styles.scanButtonSubtext}>
              Scan student QR code to process payment
            </Text>
          </TouchableOpacity>

          <TouchableOpacity
            style={styles.faceButton}
            onPress={() => navigation.navigate('FaceScanner')}
          >
            <Text style={styles.faceButtonText}>üë§ Face Recognition</Text>
            <Text style={styles.faceButtonSubtext}>
              Use face recognition for student identification
            </Text>
          </TouchableOpacity>

          <TouchableOpacity
            style={styles.testButton}
            onPress={() => {
              Alert.alert(
                'Test QR Codes',
                'For testing, use these student IDs in any QR code generator:\n\nSTU001, STU002, STU003, STU004, STU005\n\nThen scan the generated QR code with the app.',
                [{ text: 'OK' }]
              );
            }}
          >
            <Text style={styles.testButtonText}>üß™ Test QR Codes</Text>
            <Text style={styles.testButtonSubtext}>
              View test student IDs for QR code generation
            </Text>
          </TouchableOpacity>

          <View style={styles.statsContainer}>
            <View style={styles.statCard}>
              <Text style={styles.statNumber}>156</Text>
              <Text style={styles.statLabel}>Today's Transactions</Text>
            </View>
            
            <View style={styles.statCard}>
              <Text style={styles.statNumber}>$12,450</Text>
              <Text style={styles.statLabel}>Today's Revenue</Text>
            </View>
          </View>
        </View>

        <View style={styles.card}>
          <Text style={styles.cardTitle}>Recent Activity</Text>
          <View style={styles.activityItem}>
            <Text style={styles.activityText}>Payment processed for John Smith</Text>
            <Text style={styles.activityTime}>2 minutes ago</Text>
          </View>
          <View style={styles.activityItem}>
            <Text style={styles.activityText}>Payment processed for Sarah Johnson</Text>
            <Text style={styles.activityTime}>5 minutes ago</Text>
          </View>
          <View style={styles.activityItem}>
            <Text style={styles.activityText}>Payment processed for Michael Chen</Text>
            <Text style={styles.activityTime}>8 minutes ago</Text>
          </View>
        </View>
      </View>
    </SafeAreaView>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#f8f9fa',
  },
  header: {
    padding: 20,
    backgroundColor: '#fff',
    borderBottomWidth: 1,
    borderBottomColor: '#e9ecef',
  },
  title: {
    fontSize: 28,
    fontWeight: 'bold',
    color: '#2c3e50',
    marginBottom: 5,
  },
  subtitle: {
    fontSize: 16,
    color: '#7f8c8d',
  },
  content: {
    flex: 1,
    padding: 20,
  },
  card: {
    backgroundColor: '#fff',
    borderRadius: 12,
    padding: 20,
    marginBottom: 20,
    shadowColor: '#000',
    shadowOffset: {
      width: 0,
      height: 2,
    },
    shadowOpacity: 0.1,
    shadowRadius: 3.84,
    elevation: 5,
  },
  cardTitle: {
    fontSize: 18,
    fontWeight: 'bold',
    color: '#2c3e50',
    marginBottom: 15,
  },
  scanButton: {
    backgroundColor: '#3498db',
    paddingVertical: 15,
    paddingHorizontal: 20,
    borderRadius: 10,
    marginBottom: 20,
  },
  scanButtonText: {
    color: '#fff',
    fontSize: 18,
    fontWeight: 'bold',
    textAlign: 'center',
  },
  scanButtonSubtext: {
    color: '#bdc3c7',
    fontSize: 14,
    textAlign: 'center',
    marginTop: 5,
  },
  faceButton: {
    backgroundColor: '#e74c3c',
    paddingVertical: 15,
    paddingHorizontal: 20,
    borderRadius: 10,
    marginBottom: 20,
  },
  faceButtonText: {
    color: '#fff',
    fontSize: 18,
    fontWeight: 'bold',
    textAlign: 'center',
  },
  faceButtonSubtext: {
    color: '#bdc3c7',
    fontSize: 14,
    textAlign: 'center',
    marginTop: 5,
  },
  testButton: {
    backgroundColor: '#9b59b6',
    paddingVertical: 15,
    paddingHorizontal: 20,
    borderRadius: 10,
    marginBottom: 20,
  },
  testButtonText: {
    color: '#fff',
    fontSize: 18,
    fontWeight: 'bold',
    textAlign: 'center',
  },
  testButtonSubtext: {
    color: '#bdc3c7',
    fontSize: 14,
    textAlign: 'center',
    marginTop: 5,
  },
  qrGeneratorButton: {
    backgroundColor: '#27ae60',
    paddingVertical: 15,
    paddingHorizontal: 20,
    borderRadius: 10,
    marginBottom: 20,
  },
  qrGeneratorButtonText: {
    color: '#fff',
    fontSize: 18,
    fontWeight: 'bold',
    textAlign: 'center',
  },
  qrGeneratorButtonSubtext: {
    color: '#bdc3c7',
    fontSize: 14,
    textAlign: 'center',
    marginTop: 5,
  },
  statsContainer: {
    flexDirection: 'row',
    justifyContent: 'space-between',
  },
  statCard: {
    flex: 1,
    backgroundColor: '#f8f9fa',
    padding: 15,
    borderRadius: 8,
    marginHorizontal: 5,
  },
  statNumber: {
    fontSize: 20,
    fontWeight: 'bold',
    color: '#2c3e50',
    textAlign: 'center',
  },
  statLabel: {
    fontSize: 12,
    color: '#7f8c8d',
    textAlign: 'center',
    marginTop: 5,
  },
  activityItem: {
    paddingVertical: 10,
    borderBottomWidth: 1,
    borderBottomColor: '#e9ecef',
  },
  activityText: {
    fontSize: 14,
    color: '#2c3e50',
  },
  activityTime: {
    fontSize: 12,
    color: '#7f8c8d',
    marginTop: 2,
  },
});

export default Dashboard;
</file>

<file path="src/screens/PaymentScreen.tsx">
import React, { useState } from 'react';
import {
  View,
  Text,
  StyleSheet,
  TouchableOpacity,
  SafeAreaView,
  StatusBar,
  Alert,
  ActivityIndicator,
  ScrollView,
} from 'react-native';
import { StackNavigationProp } from '@react-navigation/stack';
import { RouteProp } from '@react-navigation/native';
import { RootStackParamList, Student } from '../types';
import { processPayment } from '../services/mockApi';

type PaymentScreenNavigationProp = StackNavigationProp<RootStackParamList, 'PaymentScreen'>;
type PaymentScreenRouteProp = RouteProp<RootStackParamList, 'PaymentScreen'>;

interface Props {
  navigation: PaymentScreenNavigationProp;
  route: PaymentScreenRouteProp;
}

const PaymentScreen: React.FC<Props> = ({ navigation, route }) => {
  const { student } = route.params;
  const [isProcessing, setIsProcessing] = useState(false);
  const [paymentAmount, setPaymentAmount] = useState(student.balance.toString());

  const handleProcessPayment = async () => {
    if (!paymentAmount || parseFloat(paymentAmount) <= 0) {
      Alert.alert('Invalid Amount', 'Please enter a valid payment amount.');
      return;
    }

    setIsProcessing(true);

    try {
      const result = await processPayment(
        student.id,
        parseFloat(paymentAmount),
        'Credit Card'
      );

      if (result.success) {
        Alert.alert(
          'Payment Successful!',
          `Payment processed successfully.\nReference: ${result.reference}`,
          [
            {
              text: 'OK',
              onPress: () => navigation.navigate('Dashboard'),
            },
          ]
        );
      } else {
        Alert.alert('Payment Failed', 'Payment processing failed. Please try again.');
      }
    } catch (error) {
      Alert.alert('Error', 'An error occurred while processing payment.');
    } finally {
      setIsProcessing(false);
    }
  };

  const handleCancel = () => {
    Alert.alert(
      'Cancel Payment',
      'Are you sure you want to cancel this payment?',
      [
        {
          text: 'No',
          style: 'cancel',
        },
        {
          text: 'Yes',
          onPress: () => navigation.navigate('Dashboard'),
        },
      ]
    );
  };

  return (
    <SafeAreaView style={styles.container}>
      <StatusBar barStyle="dark-content" backgroundColor="#f8f9fa" />
      
      <View style={styles.header}>
        <TouchableOpacity onPress={handleCancel} style={styles.cancelButton}>
          <Text style={styles.cancelButtonText}>‚úï Cancel</Text>
        </TouchableOpacity>
        <Text style={styles.headerTitle}>Payment Details</Text>
        <View style={styles.placeholder} />
      </View>

      <ScrollView style={styles.content}>
        <View style={styles.studentCard}>
          <Text style={styles.cardTitle}>Student Information</Text>
          
          <View style={styles.infoRow}>
            <Text style={styles.label}>Name:</Text>
            <Text style={styles.value}>{student.name}</Text>
          </View>
          
          <View style={styles.infoRow}>
            <Text style={styles.label}>Student ID:</Text>
            <Text style={styles.value}>{student.studentId}</Text>
          </View>
          
          <View style={styles.infoRow}>
            <Text style={styles.label}>Department:</Text>
            <Text style={styles.value}>{student.department}</Text>
          </View>
          
          <View style={styles.infoRow}>
            <Text style={styles.label}>Email:</Text>
            <Text style={styles.value}>{student.email}</Text>
          </View>
          
          <View style={styles.infoRow}>
            <Text style={styles.label}>Phone:</Text>
            <Text style={styles.value}>{student.phone}</Text>
          </View>
          
          <View style={styles.infoRow}>
            <Text style={styles.label}>Semester:</Text>
            <Text style={styles.value}>{student.semester}</Text>
          </View>
        </View>

        <View style={styles.paymentCard}>
          <Text style={styles.cardTitle}>Payment Information</Text>
          
          <View style={styles.balanceRow}>
            <Text style={styles.balanceLabel}>Current Balance:</Text>
            <Text style={styles.balanceAmount}>${student.balance.toFixed(2)}</Text>
          </View>
          
          <View style={styles.paymentMethodRow}>
            <Text style={styles.label}>Payment Method:</Text>
            <Text style={styles.value}>Credit Card</Text>
          </View>
          
          <View style={styles.paymentMethodRow}>
            <Text style={styles.label}>Payment Amount:</Text>
            <Text style={styles.value}>${paymentAmount}</Text>
          </View>
        </View>

        <TouchableOpacity
          style={[styles.processButton, isProcessing && styles.processButtonDisabled]}
          onPress={handleProcessPayment}
          disabled={isProcessing}
        >
          {isProcessing ? (
            <ActivityIndicator color="#fff" size="small" />
          ) : (
            <Text style={styles.processButtonText}>Process Payment</Text>
          )}
        </TouchableOpacity>
      </ScrollView>
    </SafeAreaView>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: '#f8f9fa',
  },
  header: {
    flexDirection: 'row',
    alignItems: 'center',
    justifyContent: 'space-between',
    padding: 20,
    backgroundColor: '#fff',
    borderBottomWidth: 1,
    borderBottomColor: '#e9ecef',
  },
  cancelButton: {
    padding: 8,
  },
  cancelButtonText: {
    color: '#e74c3c',
    fontSize: 16,
    fontWeight: '600',
  },
  headerTitle: {
    fontSize: 18,
    fontWeight: 'bold',
    color: '#2c3e50',
  },
  placeholder: {
    width: 60,
  },
  content: {
    flex: 1,
    padding: 20,
  },
  studentCard: {
    backgroundColor: '#fff',
    borderRadius: 12,
    padding: 20,
    marginBottom: 20,
    shadowColor: '#000',
    shadowOffset: {
      width: 0,
      height: 2,
    },
    shadowOpacity: 0.1,
    shadowRadius: 3.84,
    elevation: 5,
  },
  paymentCard: {
    backgroundColor: '#fff',
    borderRadius: 12,
    padding: 20,
    marginBottom: 30,
    shadowColor: '#000',
    shadowOffset: {
      width: 0,
      height: 2,
    },
    shadowOpacity: 0.1,
    shadowRadius: 3.84,
    elevation: 5,
  },
  cardTitle: {
    fontSize: 18,
    fontWeight: 'bold',
    color: '#2c3e50',
    marginBottom: 15,
  },
  infoRow: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    paddingVertical: 8,
    borderBottomWidth: 1,
    borderBottomColor: '#f1f2f6',
  },
  label: {
    fontSize: 14,
    color: '#7f8c8d',
    flex: 1,
  },
  value: {
    fontSize: 14,
    color: '#2c3e50',
    fontWeight: '600',
    flex: 2,
    textAlign: 'right',
  },
  balanceRow: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    paddingVertical: 12,
    backgroundColor: '#f8f9fa',
    paddingHorizontal: 15,
    borderRadius: 8,
    marginBottom: 15,
  },
  balanceLabel: {
    fontSize: 16,
    color: '#2c3e50',
    fontWeight: '600',
  },
  balanceAmount: {
    fontSize: 18,
    color: '#e74c3c',
    fontWeight: 'bold',
  },
  paymentMethodRow: {
    flexDirection: 'row',
    justifyContent: 'space-between',
    alignItems: 'center',
    paddingVertical: 8,
    borderBottomWidth: 1,
    borderBottomColor: '#f1f2f6',
  },
  processButton: {
    backgroundColor: '#27ae60',
    paddingVertical: 16,
    borderRadius: 10,
    alignItems: 'center',
    marginBottom: 20,
  },
  processButtonDisabled: {
    backgroundColor: '#95a5a6',
  },
  processButtonText: {
    color: '#fff',
    fontSize: 18,
    fontWeight: 'bold',
  },
});

export default PaymentScreen;
</file>

<file path="src/services/faceRecognitionApi.ts">
export interface FaceRecognitionRequest {
  embedding: number[];
  userId?: string;
  sessionId?: string;
}

export interface FaceRecognitionResponse {
  success: boolean;
  userId?: string;
  userName?: string;
  confidence?: number;
  message?: string;
  error?: string;
}

/**
 * Sends face embedding to backend for recognition
 * 
 * @param embedding - 128-dimensional face embedding vector
 * @param options - Additional options for the request
 * @returns Recognition result from the backend
 */
export const recognizeFace = async (
  embedding: number[],
  options: { userId?: string; sessionId?: string } = {}
): Promise<FaceRecognitionResponse> => {
  try {
    const requestBody: FaceRecognitionRequest = {
      embedding,
      ...options
    };

    const response = await fetch('https://your-backend.com/api/face-recognition', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        // Add any authentication headers here
        // 'Authorization': `Bearer ${token}`,
      },
      body: JSON.stringify(requestBody),
    });

    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }

    const result: FaceRecognitionResponse = await response.json();
    return result;

  } catch (error) {
    console.error('Face recognition API error:', error);
    return {
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error occurred'
    };
  }
};

/**
 * Registers a new face embedding in the system
 * 
 * @param embedding - 128-dimensional face embedding vector
 * @param userData - User information to associate with the face
 * @returns Registration result
 */
export const registerFace = async (
  embedding: number[],
  userData: { userId: string; userName: string; email?: string }
): Promise<FaceRecognitionResponse> => {
  try {
    const requestBody = {
      embedding,
      ...userData
    };

    const response = await fetch('https://your-backend.com/api/face-registration', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        // Add any authentication headers here
        // 'Authorization': `Bearer ${token}`,
      },
      body: JSON.stringify(requestBody),
    });

    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }

    const result: FaceRecognitionResponse = await response.json();
    return result;

  } catch (error) {
    console.error('Face registration API error:', error);
    return {
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error occurred'
    };
  }
};

/**
 * Updates an existing face embedding
 * 
 * @param userId - User ID to update
 * @param embedding - New 128-dimensional face embedding vector
 * @returns Update result
 */
export const updateFaceEmbedding = async (
  userId: string,
  embedding: number[]
): Promise<FaceRecognitionResponse> => {
  try {
    const requestBody = {
      userId,
      embedding
    };

    const response = await fetch('https://your-backend.com/api/face-update', {
      method: 'PUT',
      headers: {
        'Content-Type': 'application/json',
        // Add any authentication headers here
        // 'Authorization': `Bearer ${token}`,
      },
      body: JSON.stringify(requestBody),
    });

    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }

    const result: FaceRecognitionResponse = await response.json();
    return result;

  } catch (error) {
    console.error('Face update API error:', error);
    return {
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error occurred'
    };
  }
};

/**
 * Deletes a face embedding from the system
 * 
 * @param userId - User ID to delete
 * @returns Deletion result
 */
export const deleteFaceEmbedding = async (
  userId: string
): Promise<FaceRecognitionResponse> => {
  try {
    const response = await fetch(`https://your-backend.com/api/face-delete/${userId}`, {
      method: 'DELETE',
      headers: {
        'Content-Type': 'application/json',
        // Add any authentication headers here
        // 'Authorization': `Bearer ${token}`,
      },
    });

    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }

    const result: FaceRecognitionResponse = await response.json();
    return result;

  } catch (error) {
    console.error('Face deletion API error:', error);
    return {
      success: false,
      error: error instanceof Error ? error.message : 'Unknown error occurred'
    };
  }
};
</file>

<file path="src/services/mockApi.ts">
import { Student } from '../types';

// Mock student database
const mockStudents: Record<string, Student> = {
  'STU001': {
    id: 'STU001',
    name: 'John Smith',
    email: 'john.smith@university.edu',
    phone: '+1-555-0123',
    department: 'Computer Science',
    balance: 1250.00,
    studentId: 'STU001',
    semester: 'Fall 2024',
    year: '2024'
  },
  'STU002': {
    id: 'STU002',
    name: 'Sarah Johnson',
    email: 'sarah.johnson@university.edu',
    phone: '+1-555-0124',
    department: 'Business Administration',
    balance: 850.50,
    studentId: 'STU002',
    semester: 'Fall 2024',
    year: '2024'
  },
  'STU003': {
    id: 'STU003',
    name: 'Michael Chen',
    email: 'michael.chen@university.edu',
    phone: '+1-555-0125',
    department: 'Engineering',
    balance: 2100.75,
    studentId: 'STU003',
    semester: 'Fall 2024',
    year: '2024'
  },
  'STU004': {
    id: 'STU004',
    name: 'Emily Davis',
    email: 'emily.davis@university.edu',
    phone: '+1-555-0126',
    department: 'Arts & Humanities',
    balance: 675.25,
    studentId: 'STU004',
    semester: 'Fall 2024',
    year: '2024'
  },
  'STU005': {
    id: 'STU005',
    name: 'David Wilson',
    email: 'david.wilson@university.edu',
    phone: '+1-555-0127',
    department: 'Medicine',
    balance: 3200.00,
    studentId: 'STU005',
    semester: 'Fall 2024',
    year: '2024'
  }
};

export const fetchStudentDetails = async (studentId: string): Promise<Student> => {
  // Simulate API delay
  await new Promise(resolve => setTimeout(resolve, 1000));
  
  const student = mockStudents[studentId];
  
  if (!student) {
    throw new Error(`Student with ID ${studentId} not found`);
  }
  
  return student;
};

export const processPayment = async (
  studentId: string, 
  amount: number, 
  paymentMethod: string
): Promise<{ success: boolean; reference: string }> => {
  // Simulate API delay
  await new Promise(resolve => setTimeout(resolve, 1500));
  
  // Generate a random payment reference
  const reference = `PAY-${Date.now()}-${Math.random().toString(36).substr(2, 9).toUpperCase()}`;
  
  // Simulate payment processing
  const success = Math.random() > 0.1; // 90% success rate
  
  return {
    success,
    reference: success ? reference : ''
  };
};
</file>

<file path="src/types.ts">
export interface Student {
  id: string;
  name: string;
  email: string;
  phone: string;
  department: string;
  balance: number;
  studentId: string;
  semester: string;
  year: string;
}

export interface PaymentDetails {
  student: Student;
  amount: number;
  paymentMethod: string;
  reference: string;
}

export type RootStackParamList = {
  Dashboard: undefined;
  QrScanner: undefined;
  FaceScanner: undefined;
  PaymentScreen: { student: Student };
};
</file>

<file path="src/utils/imageProcessing.ts">
export interface FaceBounds {
  x: number;
  y: number;
  width: number;
  height: number;
}

export interface ProcessedImage {
  data: number[];
  width: number;
  height: number;
}

/**
 * Crops and preprocesses an image based on face detection bounds
 * This is a placeholder function - you'll need to implement this using react-native-skia
 * 
 * @param imagePath - Path to the captured image
 * @param faceBounds - Bounding box of the detected face
 * @param targetSize - Target size for the processed image (e.g., 160 for FaceNet)
 * @returns Processed image data ready for TensorFlow Lite
 */
export const cropAndPreprocessImage = async (
  imagePath: string,
  faceBounds: FaceBounds,
  targetSize: number = 160
): Promise<Float32Array> => {
  try {
    console.log('Image processing placeholder - implement with react-native-skia');
    console.log('Image path:', imagePath);
    console.log('Face bounds:', faceBounds);
    console.log('Target size:', targetSize);
    
    // TODO: Implement using react-native-skia
    // This function should:
    // 1. Load the image from imagePath
    // 2. Crop to the face bounds with padding
    // 3. Resize to targetSize x targetSize
    // 4. Normalize pixel values to [0, 1] or [-1, 1] depending on your model
    // 5. Return processed data
    
    // Placeholder return - replace with actual implementation
    const normalizedData = new Float32Array(targetSize * targetSize * 3);
    for (let i = 0; i < normalizedData.length; i++) {
      normalizedData[i] = (Math.random() - 0.5) * 2; // Random values between -1 and 1
    }
    
    return normalizedData;
  } catch (error) {
    console.error('Error in image processing:', error);
    // Fallback to placeholder data if processing fails
    return new Float32Array(targetSize * targetSize * 3).fill(0.5);
  }
};

/**
 * Converts processed image data to the format expected by TensorFlow Lite
 * 
 * @param processedImage - The processed image data
 * @returns Buffer ready for TensorFlow Lite inference
 */
export const prepareForTensorFlowLite = (processedImage: ProcessedImage): number[] => {
  // TODO: Implement based on your specific TFLite model requirements
  // This might involve:
  // - Converting RGB to BGR
  // - Normalizing to specific ranges
  // - Reshaping the data
  
  return processedImage.data;
};

/**
 * Calculates face embedding similarity using cosine similarity
 * 
 * @param embedding1 - First face embedding (128-dimensional vector)
 * @param embedding2 - Second face embedding (128-dimensional vector)
 * @returns Similarity score between 0 and 1
 */
export const calculateFaceSimilarity = (embedding1: number[], embedding2: number[]): number => {
  if (embedding1.length !== embedding2.length) {
    throw new Error('Embeddings must have the same length');
  }
  
  let dotProduct = 0;
  let norm1 = 0;
  let norm2 = 0;
  
  for (let i = 0; i < embedding1.length; i++) {
    dotProduct += embedding1[i] * embedding2[i];
    norm1 += embedding1[i] * embedding1[i];
    norm2 += embedding2[i] * embedding2[i];
  }
  
  const similarity = dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
  return Math.max(0, Math.min(1, similarity)); // Clamp between 0 and 1
};

/**
 * Determines if two faces are the same person based on similarity threshold
 * 
 * @param embedding1 - First face embedding
 * @param embedding2 - Second face embedding
 * @param threshold - Similarity threshold (typically 0.6-0.8 for FaceNet)
 * @returns True if faces are considered the same person
 */
export const isSamePerson = (
  embedding1: number[], 
  embedding2: number[], 
  threshold: number = 0.7
): boolean => {
  const similarity = calculateFaceSimilarity(embedding1, embedding2);
  return similarity >= threshold;
};
</file>

<file path="src/utils/QRCodeGenerator.tsx">
import React from 'react';
import { View, Text, StyleSheet, TouchableOpacity, Alert } from 'react-native';

const QRCodeGenerator: React.FC = () => {
  const studentIds = ['STU001', 'STU002', 'STU003', 'STU004', 'STU005'];

  const generateQRCode = (studentId: string) => {
    // In a real app, you would generate an actual QR code image
    // For now, we'll just show the student ID that should be in the QR code
    Alert.alert(
      'QR Code Content',
      `Student ID: ${studentId}\n\nThis is what should be encoded in the QR code. In a real implementation, this would be an actual QR code image that can be scanned.`,
      [
        { text: 'OK' },
        { 
          text: 'Copy ID', 
          onPress: () => {
            // In a real app, you would copy to clipboard
            Alert.alert('Copied', `Student ID ${studentId} copied to clipboard`);
          }
        }
      ]
    );
  };

  return (
    <View style={styles.container}>
      <Text style={styles.title}>Test QR Codes</Text>
      <Text style={styles.subtitle}>
        These are the student IDs that should be encoded in QR codes for testing:
      </Text>
      
      {studentIds.map((studentId) => (
        <TouchableOpacity
          key={studentId}
          style={styles.qrButton}
          onPress={() => generateQRCode(studentId)}
        >
          <Text style={styles.qrButtonText}>üì± {studentId}</Text>
          <Text style={styles.qrButtonSubtext}>Tap to view QR content</Text>
        </TouchableOpacity>
      ))}
      
      <View style={styles.infoCard}>
        <Text style={styles.infoTitle}>Testing Instructions:</Text>
        <Text style={styles.infoText}>
          1. Use any QR code generator online{'\n'}
          2. Encode one of the student IDs above{'\n'}
          3. Scan the generated QR code with the app{'\n'}
          4. The app will fetch student details and show payment screen
        </Text>
      </View>
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
    padding: 20,
    backgroundColor: '#f8f9fa',
  },
  title: {
    fontSize: 24,
    fontWeight: 'bold',
    color: '#2c3e50',
    textAlign: 'center',
    marginBottom: 10,
  },
  subtitle: {
    fontSize: 16,
    color: '#7f8c8d',
    textAlign: 'center',
    marginBottom: 30,
  },
  qrButton: {
    backgroundColor: '#fff',
    padding: 20,
    borderRadius: 12,
    marginBottom: 15,
    shadowColor: '#000',
    shadowOffset: {
      width: 0,
      height: 2,
    },
    shadowOpacity: 0.1,
    shadowRadius: 3.84,
    elevation: 5,
  },
  qrButtonText: {
    fontSize: 18,
    fontWeight: 'bold',
    color: '#2c3e50',
    textAlign: 'center',
  },
  qrButtonSubtext: {
    fontSize: 14,
    color: '#7f8c8d',
    textAlign: 'center',
    marginTop: 5,
  },
  infoCard: {
    backgroundColor: '#fff',
    padding: 20,
    borderRadius: 12,
    marginTop: 20,
    shadowColor: '#000',
    shadowOffset: {
      width: 0,
      height: 2,
    },
    shadowOpacity: 0.1,
    shadowRadius: 3.84,
    elevation: 5,
  },
  infoTitle: {
    fontSize: 18,
    fontWeight: 'bold',
    color: '#2c3e50',
    marginBottom: 10,
  },
  infoText: {
    fontSize: 14,
    color: '#7f8c8d',
    lineHeight: 20,
  },
});

export default QRCodeGenerator;
</file>

<file path="TESTING_GUIDE.md">
# QR Scanner Testing Guide

## üß™ **Testing the QR Scanner with Mock Data**

### **Step 1: Generate Test QR Codes**

1. **Open the App**
   - Launch the merchant app
   - Navigate to Dashboard
   - Tap "üì± QR Code Generator"

2. **View QR Code Content**
   - Select any student from the list
   - Tap "View Content" to see the JSON data
   - Copy the JSON content (this is what will be in the QR code)

3. **Generate QR Code**
   - Use any online QR code generator:
     - [QR Code Generator](https://www.qr-code-generator.com/)
     - [QR Server](https://api.qrserver.com/v1/create-qr-code/)
     - [QR Code Monkey](https://www.qrcode-monkey.com/)
   - Paste the JSON content as the QR code data
   - Generate and download the QR code image

### **Step 2: Test QR Scanning**

1. **Open QR Scanner**
   - From Dashboard, tap "üì± Scan Student QR Code"
   - Grant camera permissions if prompted

2. **Scan the Generated QR Code**
   - Point the camera at the generated QR code
   - The app should detect the QR code and extract student data
   - Verify the student details are displayed correctly

3. **Test Navigation Flow**
   - After scanning, the app should navigate to PaymentScreen
   - Verify all student details are passed correctly
   - Test the payment processing functionality

### **Step 3: Test Different Scenarios**

#### **Valid QR Codes**
Test with these student IDs:
- **STU001** - John Smith (Computer Science, $1250.00)
- **STU002** - Sarah Johnson (Business Administration, $850.50)
- **STU003** - Michael Chen (Engineering, $2100.75)
- **STU004** - Emily Davis (Arts & Humanities, $675.25)
- **STU005** - David Wilson (Medicine, $3200.00)

#### **Invalid QR Codes**
Test error handling with:
- Empty QR codes
- Invalid JSON format
- Unknown student IDs
- Malformed data

### **Step 4: Verify Data Flow**

#### **QR Code Content Format**
```json
{
  "id": "STU001",
  "name": "John Smith",
  "email": "john.smith@university.edu",
  "phone": "+1-555-0123",
  "department": "Computer Science",
  "balance": 1250.00,
  "studentId": "STU001",
  "semester": "Fall 2024",
  "year": "2024"
}
```

#### **Expected Flow**
1. **QR Code Scanned** ‚Üí Extract JSON data
2. **Parse Student Data** ‚Üí Convert JSON to Student object
3. **Fetch Details** ‚Üí Call mock API with student ID
4. **Display Details** ‚Üí Show student information
5. **Navigate to Payment** ‚Üí Pass student data to PaymentScreen
6. **Process Payment** ‚Üí Handle payment with student details

### **Step 5: Test Mock API Integration**

#### **Mock API Endpoints**
- `fetchStudentDetails(studentId)` - Fetches student data
- `processPayment(studentId, amount, method)` - Processes payment

#### **Test Cases**
1. **Valid Student ID**
   - Should return student details
   - Should navigate to PaymentScreen
   - Should display correct balance

2. **Invalid Student ID**
   - Should show error message
   - Should not navigate to PaymentScreen
   - Should allow rescanning

3. **Payment Processing**
   - Should show loading indicator
   - Should display success/failure message
   - Should return to Dashboard on success

### **Step 6: Debugging Tips**

#### **Common Issues**
1. **Camera Permission Denied**
   - Check app permissions in device settings
   - Restart app after granting permissions

2. **QR Code Not Detected**
   - Ensure good lighting
   - Hold camera steady
   - Try different QR code sizes

3. **Navigation Issues**
   - Check console for navigation errors
   - Verify screen names in navigation stack
   - Ensure proper parameter passing

#### **Console Logging**
Add these logs to debug:
```typescript
console.log('QR Code Scanned:', scannedData);
console.log('Student Data:', studentData);
console.log('Navigation Params:', route.params);
```

### **Step 7: Performance Testing**

#### **Test Scenarios**
1. **Multiple QR Codes**
   - Scan different QR codes rapidly
   - Verify no memory leaks
   - Check app responsiveness

2. **Large QR Codes**
   - Test with complex JSON data
   - Verify parsing performance
   - Check memory usage

3. **Error Recovery**
   - Test with corrupted QR codes
   - Verify error handling
   - Check app stability

### **Step 8: Integration Testing**

#### **End-to-End Flow**
1. **Dashboard** ‚Üí **QR Scanner** ‚Üí **Payment Screen** ‚Üí **Dashboard**
2. **QR Code Generation** ‚Üí **QR Scanner** ‚Üí **Payment Processing**
3. **Error Handling** ‚Üí **Retry Mechanism** ‚Üí **Success Flow**

#### **Test Checklist**
- [ ] QR code generation works
- [ ] Camera permissions granted
- [ ] QR code detection works
- [ ] Student data parsing works
- [ ] Mock API integration works
- [ ] Navigation flow works
- [ ] Payment processing works
- [ ] Error handling works
- [ ] UI responsiveness maintained

### **Step 9: Manual Testing Steps**

1. **Generate QR Code**
   ```
   JSON Content: {"id":"STU001","name":"John Smith","email":"john.smith@university.edu","phone":"+1-555-0123","department":"Computer Science","balance":1250.00,"studentId":"STU001","semester":"Fall 2024","year":"2024"}
   ```

2. **Scan QR Code**
   - Open app ‚Üí Dashboard ‚Üí Scan QR Code
   - Point camera at generated QR code
   - Verify student details appear

3. **Process Payment**
   - Navigate to PaymentScreen
   - Verify student details are correct
   - Tap "Process Payment"
   - Verify success/failure handling

4. **Return to Dashboard**
   - After payment, should return to Dashboard
   - Verify app state is reset properly

### **Step 10: Automated Testing (Future)**

#### **Unit Tests**
```typescript
// Test QR code parsing
test('should parse valid QR code data', () => {
  const qrData = '{"studentId":"STU001","name":"John Smith"}';
  const result = parseQRData(qrData);
  expect(result.studentId).toBe('STU001');
});

// Test mock API
test('should fetch student details', async () => {
  const student = await fetchStudentDetails('STU001');
  expect(student.name).toBe('John Smith');
});
```

#### **Integration Tests**
```typescript
// Test complete flow
test('should scan QR and process payment', async () => {
  // Mock QR scan
  // Verify navigation
  // Test payment processing
});
```

This testing guide ensures comprehensive validation of the QR scanner functionality with mock data!
</file>

<file path="__tests__/App.test.tsx">
/**
 * @format
 */

import React from 'react';
import ReactTestRenderer from 'react-test-renderer';
import App from '../App';

test('renders correctly', async () => {
  await ReactTestRenderer.act(() => {
    ReactTestRenderer.create(<App />);
  });
});
</file>

<file path=".eslintrc.js">
module.exports = {
  root: true,
  extends: '@react-native',
};
</file>

<file path=".gitignore">
# OSX
#
.DS_Store

# Xcode
#
build/
*.pbxuser
!default.pbxuser
*.mode1v3
!default.mode1v3
*.mode2v3
!default.mode2v3
*.perspectivev3
!default.perspectivev3
xcuserdata
*.xccheckout
*.moved-aside
DerivedData
*.hmap
*.ipa
*.xcuserstate
**/.xcode.env.local

# Android/IntelliJ
#
build/
.idea
.gradle
local.properties
*.iml
*.hprof
.cxx/
*.keystore
!debug.keystore
.kotlin/

# node.js
#
node_modules/
npm-debug.log
yarn-error.log

# fastlane
#
# It is recommended to not store the screenshots in the git repo. Instead, use fastlane to re-generate the
# screenshots whenever they are needed.
# For more information about the recommended setup visit:
# https://docs.fastlane.tools/best-practices/source-control/

**/fastlane/report.xml
**/fastlane/Preview.html
**/fastlane/screenshots
**/fastlane/test_output

# Bundle artifact
*.jsbundle

# Ruby / CocoaPods
**/Pods/
/vendor/bundle/

# Temporary files created by Metro to check the health of the file watcher
.metro-health-check*

# testing
/coverage

# Yarn
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/sdks
!.yarn/versions
</file>

<file path=".prettierrc.js">
module.exports = {
  arrowParens: 'avoid',
  singleQuote: true,
  trailingComma: 'all',
};
</file>

<file path=".watchmanconfig">
{}
</file>

<file path="android/app/build.gradle">
apply plugin: "com.android.application"
apply plugin: "org.jetbrains.kotlin.android"
apply plugin: "com.facebook.react"

/**
 * This is the configuration block to customize your React Native Android app.
 * By default you don't need to apply any configuration, just uncomment the lines you need.
 */
react {
    /* Folders */
    //   The root of your project, i.e. where "package.json" lives. Default is '../..'
    // root = file("../../")
    //   The folder where the react-native NPM package is. Default is ../../node_modules/react-native
    // reactNativeDir = file("../../node_modules/react-native")
    //   The folder where the react-native Codegen package is. Default is ../../node_modules/@react-native/codegen
    // codegenDir = file("../../node_modules/@react-native/codegen")
    //   The cli.js file which is the React Native CLI entrypoint. Default is ../../node_modules/react-native/cli.js
    // cliFile = file("../../node_modules/react-native/cli.js")

    /* Variants */
    //   The list of variants to that are debuggable. For those we're going to
    //   skip the bundling of the JS bundle and the assets. By default is just 'debug'.
    //   If you add flavors like lite, prod, etc. you'll have to list your debuggableVariants.
    // debuggableVariants = ["liteDebug", "prodDebug"]

    /* Bundling */
    //   A list containing the node command and its flags. Default is just 'node'.
    // nodeExecutableAndArgs = ["node"]
    //
    //   The command to run when bundling. By default is 'bundle'
    // bundleCommand = "ram-bundle"
    //
    //   The path to the CLI configuration file. Default is empty.
    // bundleConfig = file(../rn-cli.config.js)
    //
    //   The name of the generated asset file containing your JS bundle
    // bundleAssetName = "MyApplication.android.bundle"
    //
    //   The entry file for bundle generation. Default is 'index.android.js' or 'index.js'
    // entryFile = file("../js/MyApplication.android.js")
    //
    //   A list of extra flags to pass to the 'bundle' commands.
    //   See https://github.com/react-native-community/cli/blob/main/docs/commands.md#bundle
    // extraPackagerArgs = []

    /* Hermes Commands */
    //   The hermes compiler command to run. By default it is 'hermesc'
    // hermesCommand = "$rootDir/my-custom-hermesc/bin/hermesc"
    //
    //   The list of flags to pass to the Hermes compiler. By default is "-O", "-output-source-map"
    // hermesFlags = ["-O", "-output-source-map"]

    /* Autolinking */
    autolinkLibrariesWithApp()
}

/**
 * Set this to true to Run Proguard on Release builds to minify the Java bytecode.
 */
def enableProguardInReleaseBuilds = false

/**
 * The preferred build flavor of JavaScriptCore (JSC)
 *
 * For example, to use the international variant, you can use:
 * `def jscFlavor = io.github.react-native-community:jsc-android-intl:2026004.+`
 *
 * The international variant includes ICU i18n library and necessary data
 * allowing to use e.g. `Date.toLocaleString` and `String.localeCompare` that
 * give correct results when using with locales other than en-US. Note that
 * this variant is about 6MiB larger per architecture than default.
 */
def jscFlavor = 'io.github.react-native-community:jsc-android:2026004.+'

android {
    ndkVersion rootProject.ext.ndkVersion
    buildToolsVersion rootProject.ext.buildToolsVersion
    compileSdk rootProject.ext.compileSdkVersion

    namespace "com.merchantapp2"
    defaultConfig {
        applicationId "com.merchantapp2"
        minSdkVersion rootProject.ext.minSdkVersion
        targetSdkVersion rootProject.ext.targetSdkVersion
        versionCode 1
        versionName "1.0"
    }
    signingConfigs {
        debug {
            storeFile file('debug.keystore')
            storePassword 'android'
            keyAlias 'androiddebugkey'
            keyPassword 'android'
        }
    }
    buildTypes {
        debug {
            signingConfig signingConfigs.debug
        }
        release {
            // Caution! In production, you need to generate your own keystore file.
            // see https://reactnative.dev/docs/signed-apk-android.
            signingConfig signingConfigs.debug
            minifyEnabled enableProguardInReleaseBuilds
            proguardFiles getDefaultProguardFile("proguard-android.txt"), "proguard-rules.pro"
        }
    }
}

dependencies {
    // The version of react-native is set by the React Native Gradle Plugin
    implementation("com.facebook.react:react-android")

    if (hermesEnabled.toBoolean()) {
        implementation("com.facebook.react:hermes-android")
    } else {
        implementation jscFlavor
    }

}
</file>

<file path="android/app/proguard-rules.pro">
# Add project specific ProGuard rules here.
# By default, the flags in this file are appended to flags specified
# in /usr/local/Cellar/android-sdk/24.3.3/tools/proguard/proguard-android.txt
# You can edit the include path and order by changing the proguardFiles
# directive in build.gradle.
#
# For more details, see
#   http://developer.android.com/guide/developing/tools/proguard.html

# Add any project specific keep options here:
</file>

<file path="android/app/src/debug/AndroidManifest.xml">
<?xml version="1.0" encoding="utf-8"?>
<manifest xmlns:android="http://schemas.android.com/apk/res/android"
    xmlns:tools="http://schemas.android.com/tools">

    <application
        android:usesCleartextTraffic="true"
        tools:targetApi="28"
        tools:ignore="GoogleAppIndexingWarning"/>
</manifest>
</file>

<file path="android/app/src/main/AndroidManifest.xml">
<manifest xmlns:android="http://schemas.android.com/apk/res/android">

    <uses-permission android:name="android.permission.INTERNET" />
    <uses-permission android:name="android.permission.CAMERA" />

    <application
      android:name=".MainApplication"
      android:label="@string/app_name"
      android:icon="@mipmap/ic_launcher"
      android:roundIcon="@mipmap/ic_launcher_round"
      android:allowBackup="false"
      android:theme="@style/AppTheme"
      android:supportsRtl="true">
      <activity
        android:name=".MainActivity"
        android:label="@string/app_name"
        android:configChanges="keyboard|keyboardHidden|orientation|screenLayout|screenSize|smallestScreenSize|uiMode"
        android:launchMode="singleTask"
        android:windowSoftInputMode="adjustResize"
        android:exported="true">
        <intent-filter>
            <action android:name="android.intent.action.MAIN" />
            <category android:name="android.intent.category.LAUNCHER" />
        </intent-filter>
      </activity>
    </application>
</manifest>
</file>

<file path="android/app/src/main/java/com/merchantapp2/MainActivity.kt">
package com.merchantapp2

import com.facebook.react.ReactActivity
import com.facebook.react.ReactActivityDelegate
import com.facebook.react.defaults.DefaultNewArchitectureEntryPoint.fabricEnabled
import com.facebook.react.defaults.DefaultReactActivityDelegate

class MainActivity : ReactActivity() {

  /**
   * Returns the name of the main component registered from JavaScript. This is used to schedule
   * rendering of the component.
   */
  override fun getMainComponentName(): String = "MerchantApp2"

  /**
   * Returns the instance of the [ReactActivityDelegate]. We use [DefaultReactActivityDelegate]
   * which allows you to enable New Architecture with a single boolean flags [fabricEnabled]
   */
  override fun createReactActivityDelegate(): ReactActivityDelegate =
      DefaultReactActivityDelegate(this, mainComponentName, fabricEnabled)
}
</file>

<file path="android/app/src/main/java/com/merchantapp2/MainApplication.kt">
package com.merchantapp2

import android.app.Application
import com.facebook.react.PackageList
import com.facebook.react.ReactApplication
import com.facebook.react.ReactHost
import com.facebook.react.ReactNativeApplicationEntryPoint.loadReactNative
import com.facebook.react.ReactNativeHost
import com.facebook.react.ReactPackage
import com.facebook.react.defaults.DefaultReactHost.getDefaultReactHost
import com.facebook.react.defaults.DefaultReactNativeHost

class MainApplication : Application(), ReactApplication {

  override val reactNativeHost: ReactNativeHost =
      object : DefaultReactNativeHost(this) {
        override fun getPackages(): List<ReactPackage> =
            PackageList(this).packages.apply {
              // Packages that cannot be autolinked yet can be added manually here, for example:
              // add(MyReactNativePackage())
            }

        override fun getJSMainModuleName(): String = "index"

        override fun getUseDeveloperSupport(): Boolean = BuildConfig.DEBUG

        override val isNewArchEnabled: Boolean = BuildConfig.IS_NEW_ARCHITECTURE_ENABLED
        override val isHermesEnabled: Boolean = BuildConfig.IS_HERMES_ENABLED
      }

  override val reactHost: ReactHost
    get() = getDefaultReactHost(applicationContext, reactNativeHost)

  override fun onCreate() {
    super.onCreate()
    loadReactNative(this)
  }
}
</file>

<file path="android/app/src/main/res/drawable/rn_edit_text_material.xml">
<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright (C) 2014 The Android Open Source Project

     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at

          http://www.apache.org/licenses/LICENSE-2.0

     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License.
-->
<inset xmlns:android="http://schemas.android.com/apk/res/android"
       android:insetLeft="@dimen/abc_edit_text_inset_horizontal_material"
       android:insetRight="@dimen/abc_edit_text_inset_horizontal_material"
       android:insetTop="@dimen/abc_edit_text_inset_top_material"
       android:insetBottom="@dimen/abc_edit_text_inset_bottom_material"
       >

    <selector>
        <!--
          This file is a copy of abc_edit_text_material (https://bit.ly/3k8fX7I).
          The item below with state_pressed="false" and state_focused="false" causes a NullPointerException.
          NullPointerException:tempt to invoke virtual method 'android.graphics.drawable.Drawable android.graphics.drawable.Drawable$ConstantState.newDrawable(android.content.res.Resources)'

          <item android:state_pressed="false" android:state_focused="false" android:drawable="@drawable/abc_textfield_default_mtrl_alpha"/>

          For more info, see https://bit.ly/3CdLStv (react-native/pull/29452) and https://bit.ly/3nxOMoR.
        -->
        <item android:state_enabled="false" android:drawable="@drawable/abc_textfield_default_mtrl_alpha"/>
        <item android:drawable="@drawable/abc_textfield_activated_mtrl_alpha"/>
    </selector>

</inset>
</file>

<file path="android/app/src/main/res/values/strings.xml">
<resources>
    <string name="app_name">MerchantApp2</string>
</resources>
</file>

<file path="android/app/src/main/res/values/styles.xml">
<resources>

    <!-- Base application theme. -->
    <style name="AppTheme" parent="Theme.AppCompat.DayNight.NoActionBar">
        <!-- Customize your theme here. -->
        <item name="android:editTextBackground">@drawable/rn_edit_text_material</item>
    </style>

</resources>
</file>

<file path="android/build.gradle">
buildscript {
    ext {
        buildToolsVersion = "35.0.0"
        minSdkVersion = 24
        compileSdkVersion = 35
        targetSdkVersion = 35
        ndkVersion = "27.1.12297006"
        kotlinVersion = "2.1.20"
    }
    repositories {
        google()
        mavenCentral()
    }
    dependencies {
        classpath("com.android.tools.build:gradle")
        classpath("com.facebook.react:react-native-gradle-plugin")
        classpath("org.jetbrains.kotlin:kotlin-gradle-plugin")
    }
}

apply plugin: "com.facebook.react.rootproject"
</file>

<file path="android/gradle.properties">
# Project-wide Gradle settings.

# IDE (e.g. Android Studio) users:
# Gradle settings configured through the IDE *will override*
# any settings specified in this file.

# For more details on how to configure your build environment visit
# http://www.gradle.org/docs/current/userguide/build_environment.html

# Specifies the JVM arguments used for the daemon process.
# The setting is particularly useful for tweaking memory settings.
# Default value: -Xmx512m -XX:MaxMetaspaceSize=256m
org.gradle.jvmargs=-Xmx2048m -XX:MaxMetaspaceSize=512m

# When configured, Gradle will run in incubating parallel mode.
# This option should only be used with decoupled projects. More details, visit
# http://www.gradle.org/docs/current/userguide/multi_project_builds.html#sec:decoupled_projects
# org.gradle.parallel=true

# AndroidX package structure to make it clearer which packages are bundled with the
# Android operating system, and which are packaged with your app's APK
# https://developer.android.com/topic/libraries/support-library/androidx-rn
android.useAndroidX=true

# Use this property to specify which architecture you want to build.
# You can also override it from the CLI using
# ./gradlew <task> -PreactNativeArchitectures=x86_64
reactNativeArchitectures=armeabi-v7a,arm64-v8a,x86,x86_64

# Use this property to enable support to the new architecture.
# This will allow you to use TurboModules and the Fabric render in
# your application. You should enable this flag either if you want
# to write custom TurboModules/Fabric components OR use libraries that
# are providing them.
newArchEnabled=true

# Use this property to enable or disable the Hermes JS engine.
# If set to false, you will be using JSC instead.
hermesEnabled=true
</file>

<file path="android/gradle/wrapper/gradle-wrapper.properties">
distributionBase=GRADLE_USER_HOME
distributionPath=wrapper/dists
distributionUrl=https\://services.gradle.org/distributions/gradle-8.14.1-bin.zip
networkTimeout=10000
validateDistributionUrl=true
zipStoreBase=GRADLE_USER_HOME
zipStorePath=wrapper/dists
</file>

<file path="android/gradlew">
#!/bin/sh

#
# Copyright ¬© 2015-2021 the original authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# SPDX-License-Identifier: Apache-2.0
#

##############################################################################
#
#   Gradle start up script for POSIX generated by Gradle.
#
#   Important for running:
#
#   (1) You need a POSIX-compliant shell to run this script. If your /bin/sh is
#       noncompliant, but you have some other compliant shell such as ksh or
#       bash, then to run this script, type that shell name before the whole
#       command line, like:
#
#           ksh Gradle
#
#       Busybox and similar reduced shells will NOT work, because this script
#       requires all of these POSIX shell features:
#         * functions;
#         * expansions ¬´$var¬ª, ¬´${var}¬ª, ¬´${var:-default}¬ª, ¬´${var+SET}¬ª,
#           ¬´${var#prefix}¬ª, ¬´${var%suffix}¬ª, and ¬´$( cmd )¬ª;
#         * compound commands having a testable exit status, especially ¬´case¬ª;
#         * various built-in commands including ¬´command¬ª, ¬´set¬ª, and ¬´ulimit¬ª.
#
#   Important for patching:
#
#   (2) This script targets any POSIX shell, so it avoids extensions provided
#       by Bash, Ksh, etc; in particular arrays are avoided.
#
#       The "traditional" practice of packing multiple parameters into a
#       space-separated string is a well documented source of bugs and security
#       problems, so this is (mostly) avoided, by progressively accumulating
#       options in "$@", and eventually passing that to Java.
#
#       Where the inherited environment variables (DEFAULT_JVM_OPTS, JAVA_OPTS,
#       and GRADLE_OPTS) rely on word-splitting, this is performed explicitly;
#       see the in-line comments for details.
#
#       There are tweaks for specific operating systems such as AIX, CygWin,
#       Darwin, MinGW, and NonStop.
#
#   (3) This script is generated from the Groovy template
#       https://github.com/gradle/gradle/blob/HEAD/platforms/jvm/plugins-application/src/main/resources/org/gradle/api/internal/plugins/unixStartScript.txt
#       within the Gradle project.
#
#       You can find Gradle at https://github.com/gradle/gradle/.
#
##############################################################################

# Attempt to set APP_HOME

# Resolve links: $0 may be a link
app_path=$0

# Need this for daisy-chained symlinks.
while
    APP_HOME=${app_path%"${app_path##*/}"}  # leaves a trailing /; empty if no leading path
    [ -h "$app_path" ]
do
    ls=$( ls -ld "$app_path" )
    link=${ls#*' -> '}
    case $link in             #(
      /*)   app_path=$link ;; #(
      *)    app_path=$APP_HOME$link ;;
    esac
done

# This is normally unused
# shellcheck disable=SC2034
APP_BASE_NAME=${0##*/}
# Discard cd standard output in case $CDPATH is set (https://github.com/gradle/gradle/issues/25036)
APP_HOME=$( cd -P "${APP_HOME:-./}" > /dev/null && printf '%s\n' "$PWD" ) || exit

# Use the maximum available, or set MAX_FD != -1 to use that value.
MAX_FD=maximum

warn () {
    echo "$*"
} >&2

die () {
    echo
    echo "$*"
    echo
    exit 1
} >&2

# OS specific support (must be 'true' or 'false').
cygwin=false
msys=false
darwin=false
nonstop=false
case "$( uname )" in                #(
  CYGWIN* )         cygwin=true  ;; #(
  Darwin* )         darwin=true  ;; #(
  MSYS* | MINGW* )  msys=true    ;; #(
  NONSTOP* )        nonstop=true ;;
esac

CLASSPATH="\\\"\\\""


# Determine the Java command to use to start the JVM.
if [ -n "$JAVA_HOME" ] ; then
    if [ -x "$JAVA_HOME/jre/sh/java" ] ; then
        # IBM's JDK on AIX uses strange locations for the executables
        JAVACMD=$JAVA_HOME/jre/sh/java
    else
        JAVACMD=$JAVA_HOME/bin/java
    fi
    if [ ! -x "$JAVACMD" ] ; then
        die "ERROR: JAVA_HOME is set to an invalid directory: $JAVA_HOME

Please set the JAVA_HOME variable in your environment to match the
location of your Java installation."
    fi
else
    JAVACMD=java
    if ! command -v java >/dev/null 2>&1
    then
        die "ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.

Please set the JAVA_HOME variable in your environment to match the
location of your Java installation."
    fi
fi

# Increase the maximum file descriptors if we can.
if ! "$cygwin" && ! "$darwin" && ! "$nonstop" ; then
    case $MAX_FD in #(
      max*)
        # In POSIX sh, ulimit -H is undefined. That's why the result is checked to see if it worked.
        # shellcheck disable=SC2039,SC3045
        MAX_FD=$( ulimit -H -n ) ||
            warn "Could not query maximum file descriptor limit"
    esac
    case $MAX_FD in  #(
      '' | soft) :;; #(
      *)
        # In POSIX sh, ulimit -n is undefined. That's why the result is checked to see if it worked.
        # shellcheck disable=SC2039,SC3045
        ulimit -n "$MAX_FD" ||
            warn "Could not set maximum file descriptor limit to $MAX_FD"
    esac
fi

# Collect all arguments for the java command, stacking in reverse order:
#   * args from the command line
#   * the main class name
#   * -classpath
#   * -D...appname settings
#   * --module-path (only if needed)
#   * DEFAULT_JVM_OPTS, JAVA_OPTS, and GRADLE_OPTS environment variables.

# For Cygwin or MSYS, switch paths to Windows format before running java
if "$cygwin" || "$msys" ; then
    APP_HOME=$( cygpath --path --mixed "$APP_HOME" )
    CLASSPATH=$( cygpath --path --mixed "$CLASSPATH" )

    JAVACMD=$( cygpath --unix "$JAVACMD" )

    # Now convert the arguments - kludge to limit ourselves to /bin/sh
    for arg do
        if
            case $arg in                                #(
              -*)   false ;;                            # don't mess with options #(
              /?*)  t=${arg#/} t=/${t%%/*}              # looks like a POSIX filepath
                    [ -e "$t" ] ;;                      #(
              *)    false ;;
            esac
        then
            arg=$( cygpath --path --ignore --mixed "$arg" )
        fi
        # Roll the args list around exactly as many times as the number of
        # args, so each arg winds up back in the position where it started, but
        # possibly modified.
        #
        # NB: a `for` loop captures its iteration list before it begins, so
        # changing the positional parameters here affects neither the number of
        # iterations, nor the values presented in `arg`.
        shift                   # remove old arg
        set -- "$@" "$arg"      # push replacement arg
    done
fi


# Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.
DEFAULT_JVM_OPTS='"-Xmx64m" "-Xms64m"'

# Collect all arguments for the java command:
#   * DEFAULT_JVM_OPTS, JAVA_OPTS, and optsEnvironmentVar are not allowed to contain shell fragments,
#     and any embedded shellness will be escaped.
#   * For example: A user cannot expect ${Hostname} to be expanded, as it is an environment variable and will be
#     treated as '${Hostname}' itself on the command line.

set -- \
        "-Dorg.gradle.appname=$APP_BASE_NAME" \
        -classpath "$CLASSPATH" \
        -jar "$APP_HOME/gradle/wrapper/gradle-wrapper.jar" \
        "$@"

# Stop when "xargs" is not available.
if ! command -v xargs >/dev/null 2>&1
then
    die "xargs is not available"
fi

# Use "xargs" to parse quoted args.
#
# With -n1 it outputs one arg per line, with the quotes and backslashes removed.
#
# In Bash we could simply go:
#
#   readarray ARGS < <( xargs -n1 <<<"$var" ) &&
#   set -- "${ARGS[@]}" "$@"
#
# but POSIX shell has neither arrays nor command substitution, so instead we
# post-process each arg (as a line of input to sed) to backslash-escape any
# character that might be a shell metacharacter, then use eval to reverse
# that process (while maintaining the separation between arguments), and wrap
# the whole thing up as a single "set" statement.
#
# This will of course break if any of these variables contains a newline or
# an unmatched quote.
#

eval "set -- $(
        printf '%s\n' "$DEFAULT_JVM_OPTS $JAVA_OPTS $GRADLE_OPTS" |
        xargs -n1 |
        sed ' s~[^-[:alnum:]+,./:=@_]~\\&~g; ' |
        tr '\n' ' '
    )" '"$@"'

exec "$JAVACMD" "$@"
</file>

<file path="android/gradlew.bat">
@REM Copyright (c) Meta Platforms, Inc. and affiliates.
@REM
@REM This source code is licensed under the MIT license found in the
@REM LICENSE file in the root directory of this source tree.

@rem
@rem Copyright 2015 the original author or authors.
@rem
@rem Licensed under the Apache License, Version 2.0 (the "License");
@rem you may not use this file except in compliance with the License.
@rem You may obtain a copy of the License at
@rem
@rem      https://www.apache.org/licenses/LICENSE-2.0
@rem
@rem Unless required by applicable law or agreed to in writing, software
@rem distributed under the License is distributed on an "AS IS" BASIS,
@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
@rem See the License for the specific language governing permissions and
@rem limitations under the License.
@rem
@rem SPDX-License-Identifier: Apache-2.0
@rem

@if "%DEBUG%"=="" @echo off
@rem ##########################################################################
@rem
@rem  Gradle startup script for Windows
@rem
@rem ##########################################################################

@rem Set local scope for the variables with windows NT shell
if "%OS%"=="Windows_NT" setlocal

set DIRNAME=%~dp0
if "%DIRNAME%"=="" set DIRNAME=.
@rem This is normally unused
set APP_BASE_NAME=%~n0
set APP_HOME=%DIRNAME%

@rem Resolve any "." and ".." in APP_HOME to make it shorter.
for %%i in ("%APP_HOME%") do set APP_HOME=%%~fi

@rem Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.
set DEFAULT_JVM_OPTS="-Xmx64m" "-Xms64m"

@rem Find java.exe
if defined JAVA_HOME goto findJavaFromJavaHome

set JAVA_EXE=java.exe
%JAVA_EXE% -version >NUL 2>&1
if %ERRORLEVEL% equ 0 goto execute

echo. 1>&2
echo ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH. 1>&2
echo. 1>&2
echo Please set the JAVA_HOME variable in your environment to match the 1>&2
echo location of your Java installation. 1>&2

goto fail

:findJavaFromJavaHome
set JAVA_HOME=%JAVA_HOME:"=%
set JAVA_EXE=%JAVA_HOME%/bin/java.exe

if exist "%JAVA_EXE%" goto execute

echo. 1>&2
echo ERROR: JAVA_HOME is set to an invalid directory: %JAVA_HOME% 1>&2
echo. 1>&2
echo Please set the JAVA_HOME variable in your environment to match the 1>&2
echo location of your Java installation. 1>&2

goto fail

:execute
@rem Setup the command line

set CLASSPATH=


@rem Execute Gradle
"%JAVA_EXE%" %DEFAULT_JVM_OPTS% %JAVA_OPTS% %GRADLE_OPTS% "-Dorg.gradle.appname=%APP_BASE_NAME%" -classpath "%CLASSPATH%" -jar "%APP_HOME%\gradle\wrapper\gradle-wrapper.jar" %*

:end
@rem End local scope for the variables with windows NT shell
if %ERRORLEVEL% equ 0 goto mainEnd

:fail
rem Set variable GRADLE_EXIT_CONSOLE if you need the _script_ return code instead of
rem the _cmd.exe /c_ return code!
set EXIT_CODE=%ERRORLEVEL%
if %EXIT_CODE% equ 0 set EXIT_CODE=1
if not ""=="%GRADLE_EXIT_CONSOLE%" exit %EXIT_CODE%
exit /b %EXIT_CODE%

:mainEnd
if "%OS%"=="Windows_NT" endlocal

:omega
</file>

<file path="android/settings.gradle">
pluginManagement { includeBuild("../node_modules/@react-native/gradle-plugin") }
plugins { id("com.facebook.react.settings") }
extensions.configure(com.facebook.react.ReactSettingsExtension){ ex -> ex.autolinkLibrariesFromCommand() }
rootProject.name = 'MerchantApp2'
include ':app'
includeBuild('../node_modules/@react-native/gradle-plugin')
</file>

<file path="app.json">
{
  "name": "MerchantApp2",
  "displayName": "MerchantApp2"
}
</file>

<file path="App.tsx">
import 'react-native-gesture-handler';
import React from 'react';
import { NavigationContainer } from '@react-navigation/native';
import { createStackNavigator } from '@react-navigation/stack';
import { SafeAreaProvider } from 'react-native-safe-area-context';

import Dashboard from './src/screens/Dashboard';
import QrScanner from './src/QrScanner';
import FaceScanner from './src/FaceScanner';
import PaymentScreen from './src/screens/PaymentScreen';
import { RootStackParamList } from './src/types';

const Stack = createStackNavigator<RootStackParamList>();

function App(): React.JSX.Element {
  return (
    <SafeAreaProvider>
      <NavigationContainer>
        <Stack.Navigator
          initialRouteName="Dashboard"
          screenOptions={{
            headerShown: false,
            cardStyle: { backgroundColor: '#f8f9fa' },
          }}
        >
          <Stack.Screen name="Dashboard" component={Dashboard} />
          <Stack.Screen name="QrScanner" component={QrScanner} />
          <Stack.Screen name="FaceScanner" component={FaceScanner} />
          <Stack.Screen name="PaymentScreen" component={PaymentScreen} />
        </Stack.Navigator>
      </NavigationContainer>
    </SafeAreaProvider>
  );
}

export default App;
</file>

<file path="babel.config.js">
module.exports = {
  presets: ['module:@react-native/babel-preset'],
  plugins: [
    'react-native-reanimated/plugin',
  ],
};
</file>

<file path="Gemfile">
source 'https://rubygems.org'

# You may use http://rbenv.org/ or https://rvm.io/ to install and use this version
ruby ">= 2.6.10"

# Exclude problematic versions of cocoapods and activesupport that causes build failures.
gem 'cocoapods', '>= 1.13', '!= 1.15.0', '!= 1.15.1'
gem 'activesupport', '>= 6.1.7.5', '!= 7.1.0'
gem 'xcodeproj', '< 1.26.0'
gem 'concurrent-ruby', '< 1.3.4'

# Ruby 3.4.0 has removed some libraries from the standard library.
gem 'bigdecimal'
gem 'logger'
gem 'benchmark'
gem 'mutex_m'
</file>

<file path="index.js">
/**
 * @format
 */

import { AppRegistry } from 'react-native';
import App from './App';
import { name as appName } from './app.json';

AppRegistry.registerComponent(appName, () => App);
</file>

<file path="ios/.xcode.env">
# This `.xcode.env` file is versioned and is used to source the environment
# used when running script phases inside Xcode.
# To customize your local environment, you can create an `.xcode.env.local`
# file that is not versioned.

# NODE_BINARY variable contains the PATH to the node executable.
#
# Customize the NODE_BINARY variable here.
# For example, to use nvm with brew, add the following line
# . "$(brew --prefix nvm)/nvm.sh" --no-use
export NODE_BINARY=$(command -v node)
</file>

<file path="ios/MerchantApp2.xcodeproj/project.pbxproj">
// !$*UTF8*$!
{
	archiveVersion = 1;
	classes = {
	};
	objectVersion = 54;
	objects = {

/* Begin PBXBuildFile section */
		0C80B921A6F3F58F76C31292 /* libPods-MerchantApp2.a in Frameworks */ = {isa = PBXBuildFile; fileRef = 5DCACB8F33CDC322A6C60F78 /* libPods-MerchantApp2.a */; };
		13B07FBF1A68108700A75B9A /* Images.xcassets in Resources */ = {isa = PBXBuildFile; fileRef = 13B07FB51A68108700A75B9A /* Images.xcassets */; };
		761780ED2CA45674006654EE /* AppDelegate.swift in Sources */ = {isa = PBXBuildFile; fileRef = 761780EC2CA45674006654EE /* AppDelegate.swift */; };
		81AB9BB82411601600AC10FF /* LaunchScreen.storyboard in Resources */ = {isa = PBXBuildFile; fileRef = 81AB9BB72411601600AC10FF /* LaunchScreen.storyboard */; };
/* End PBXBuildFile section */

/* Begin PBXContainerItemProxy section */
		00E356F41AD99517003FC87E /* PBXContainerItemProxy */ = {
			isa = PBXContainerItemProxy;
			containerPortal = 83CBB9F71A601CBA00E9B192 /* Project object */;
			proxyType = 1;
			remoteGlobalIDString = 13B07F861A680F5B00A75B9A;
			remoteInfo = MerchantApp2;
		};
/* End PBXContainerItemProxy section */

/* Begin PBXFileReference section */
		00E356F11AD99517003FC87E /* Info.plist */ = {isa = PBXFileReference; lastKnownFileType = text.plist.xml; path = Info.plist; sourceTree = "<group>"; };
		13B07F961A680F5B00A75B9A /* MerchantApp2.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = MerchantApp2.app; sourceTree = BUILT_PRODUCTS_DIR; };
		13B07FB51A68108700A75B9A /* Images.xcassets */ = {isa = PBXFileReference; lastKnownFileType = folder.assetcatalog; name = Images.xcassets; path = MerchantApp2/Images.xcassets; sourceTree = "<group>"; };
		13B07FB61A68108700A75B9A /* Info.plist */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = text.plist.xml; name = Info.plist; path = MerchantApp2/Info.plist; sourceTree = "<group>"; };
		13B07FB81A68108700A75B9A /* PrivacyInfo.xcprivacy */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = text.plist.xml; name = PrivacyInfo.xcprivacy; path = MerchantApp2/PrivacyInfo.xcprivacy; sourceTree = "<group>"; };
		3B4392A12AC88292D35C810B /* Pods-MerchantApp2.debug.xcconfig */ = {isa = PBXFileReference; includeInIndex = 1; lastKnownFileType = text.xcconfig; name = "Pods-MerchantApp2.debug.xcconfig"; path = "Target Support Files/Pods-MerchantApp2/Pods-MerchantApp2.debug.xcconfig"; sourceTree = "<group>"; };
		5709B34CF0A7D63546082F79 /* Pods-MerchantApp2.release.xcconfig */ = {isa = PBXFileReference; includeInIndex = 1; lastKnownFileType = text.xcconfig; name = "Pods-MerchantApp2.release.xcconfig"; path = "Target Support Files/Pods-MerchantApp2/Pods-MerchantApp2.release.xcconfig"; sourceTree = "<group>"; };
		5DCACB8F33CDC322A6C60F78 /* libPods-MerchantApp2.a */ = {isa = PBXFileReference; explicitFileType = archive.ar; includeInIndex = 0; path = "libPods-MerchantApp2.a"; sourceTree = BUILT_PRODUCTS_DIR; };
		761780EC2CA45674006654EE /* AppDelegate.swift */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.swift; name = AppDelegate.swift; path = MerchantApp2/AppDelegate.swift; sourceTree = "<group>"; };
		81AB9BB72411601600AC10FF /* LaunchScreen.storyboard */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = file.storyboard; name = LaunchScreen.storyboard; path = MerchantApp2/LaunchScreen.storyboard; sourceTree = "<group>"; };
		ED297162215061F000B7C4FE /* JavaScriptCore.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = JavaScriptCore.framework; path = System/Library/Frameworks/JavaScriptCore.framework; sourceTree = SDKROOT; };
/* End PBXFileReference section */

/* Begin PBXFrameworksBuildPhase section */
		13B07F8C1A680F5B00A75B9A /* Frameworks */ = {
			isa = PBXFrameworksBuildPhase;
			buildActionMask = 2147483647;
			files = (
				0C80B921A6F3F58F76C31292 /* libPods-MerchantApp2.a in Frameworks */,
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXFrameworksBuildPhase section */

/* Begin PBXGroup section */
		00E356F01AD99517003FC87E /* Supporting Files */ = {
			isa = PBXGroup;
			children = (
				00E356F11AD99517003FC87E /* Info.plist */,
			);
			name = "Supporting Files";
			sourceTree = "<group>";
		};
		13B07FAE1A68108700A75B9A /* MerchantApp2 */ = {
			isa = PBXGroup;
			children = (
				13B07FB51A68108700A75B9A /* Images.xcassets */,
				761780EC2CA45674006654EE /* AppDelegate.swift */,
				13B07FB61A68108700A75B9A /* Info.plist */,
				81AB9BB72411601600AC10FF /* LaunchScreen.storyboard */,
				13B07FB81A68108700A75B9A /* PrivacyInfo.xcprivacy */,
			);
			name = MerchantApp2;
			sourceTree = "<group>";
		};
		2D16E6871FA4F8E400B85C8A /* Frameworks */ = {
			isa = PBXGroup;
			children = (
				ED297162215061F000B7C4FE /* JavaScriptCore.framework */,
				5DCACB8F33CDC322A6C60F78 /* libPods-MerchantApp2.a */,
			);
			name = Frameworks;
			sourceTree = "<group>";
		};
		832341AE1AAA6A7D00B99B32 /* Libraries */ = {
			isa = PBXGroup;
			children = (
			);
			name = Libraries;
			sourceTree = "<group>";
		};
		83CBB9F61A601CBA00E9B192 = {
			isa = PBXGroup;
			children = (
				13B07FAE1A68108700A75B9A /* MerchantApp2 */,
				832341AE1AAA6A7D00B99B32 /* Libraries */,
				83CBBA001A601CBA00E9B192 /* Products */,
				2D16E6871FA4F8E400B85C8A /* Frameworks */,
				BBD78D7AC51CEA395F1C20DB /* Pods */,
			);
			indentWidth = 2;
			sourceTree = "<group>";
			tabWidth = 2;
			usesTabs = 0;
		};
		83CBBA001A601CBA00E9B192 /* Products */ = {
			isa = PBXGroup;
			children = (
				13B07F961A680F5B00A75B9A /* MerchantApp2.app */,
			);
			name = Products;
			sourceTree = "<group>";
		};
		BBD78D7AC51CEA395F1C20DB /* Pods */ = {
			isa = PBXGroup;
			children = (
				3B4392A12AC88292D35C810B /* Pods-MerchantApp2.debug.xcconfig */,
				5709B34CF0A7D63546082F79 /* Pods-MerchantApp2.release.xcconfig */,
			);
			path = Pods;
			sourceTree = "<group>";
		};
/* End PBXGroup section */

/* Begin PBXNativeTarget section */
		13B07F861A680F5B00A75B9A /* MerchantApp2 */ = {
			isa = PBXNativeTarget;
			buildConfigurationList = 13B07F931A680F5B00A75B9A /* Build configuration list for PBXNativeTarget "MerchantApp2" */;
			buildPhases = (
				C38B50BA6285516D6DCD4F65 /* [CP] Check Pods Manifest.lock */,
				13B07F871A680F5B00A75B9A /* Sources */,
				13B07F8C1A680F5B00A75B9A /* Frameworks */,
				13B07F8E1A680F5B00A75B9A /* Resources */,
				00DD1BFF1BD5951E006B06BC /* Bundle React Native code and images */,
				00EEFC60759A1932668264C0 /* [CP] Embed Pods Frameworks */,
				E235C05ADACE081382539298 /* [CP] Copy Pods Resources */,
			);
			buildRules = (
			);
			dependencies = (
			);
			name = MerchantApp2;
			productName = MerchantApp2;
			productReference = 13B07F961A680F5B00A75B9A /* MerchantApp2.app */;
			productType = "com.apple.product-type.application";
		};
/* End PBXNativeTarget section */

/* Begin PBXProject section */
		83CBB9F71A601CBA00E9B192 /* Project object */ = {
			isa = PBXProject;
			attributes = {
				LastUpgradeCheck = 1210;
				TargetAttributes = {
					13B07F861A680F5B00A75B9A = {
						LastSwiftMigration = 1120;
					};
				};
			};
			buildConfigurationList = 83CBB9FA1A601CBA00E9B192 /* Build configuration list for PBXProject "MerchantApp2" */;
			compatibilityVersion = "Xcode 12.0";
			developmentRegion = en;
			hasScannedForEncodings = 0;
			knownRegions = (
				en,
				Base,
			);
			mainGroup = 83CBB9F61A601CBA00E9B192;
			productRefGroup = 83CBBA001A601CBA00E9B192 /* Products */;
			projectDirPath = "";
			projectRoot = "";
			targets = (
				13B07F861A680F5B00A75B9A /* MerchantApp2 */,
			);
		};
/* End PBXProject section */

/* Begin PBXResourcesBuildPhase section */
		00E356EC1AD99517003FC87E /* Resources */ = {
			isa = PBXResourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
		13B07F8E1A680F5B00A75B9A /* Resources */ = {
			isa = PBXResourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
				81AB9BB82411601600AC10FF /* LaunchScreen.storyboard in Resources */,
				13B07FBF1A68108700A75B9A /* Images.xcassets in Resources */,
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXResourcesBuildPhase section */

/* Begin PBXShellScriptBuildPhase section */
		00DD1BFF1BD5951E006B06BC /* Bundle React Native code and images */ = {
			isa = PBXShellScriptBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			inputPaths = (
				"$(SRCROOT)/.xcode.env.local",
				"$(SRCROOT)/.xcode.env",
			);
			name = "Bundle React Native code and images";
			outputPaths = (
			);
			runOnlyForDeploymentPostprocessing = 0;
			shellPath = /bin/sh;
			shellScript = "set -e\n\nWITH_ENVIRONMENT=\"$REACT_NATIVE_PATH/scripts/xcode/with-environment.sh\"\nREACT_NATIVE_XCODE=\"$REACT_NATIVE_PATH/scripts/react-native-xcode.sh\"\n\n/bin/sh -c \"$WITH_ENVIRONMENT $REACT_NATIVE_XCODE\"\n";
		};
		00EEFC60759A1932668264C0 /* [CP] Embed Pods Frameworks */ = {
			isa = PBXShellScriptBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			inputFileListPaths = (
				"${PODS_ROOT}/Target Support Files/Pods-MerchantApp2/Pods-MerchantApp2-frameworks-${CONFIGURATION}-input-files.xcfilelist",
			);
			name = "[CP] Embed Pods Frameworks";
			outputFileListPaths = (
				"${PODS_ROOT}/Target Support Files/Pods-MerchantApp2/Pods-MerchantApp2-frameworks-${CONFIGURATION}-output-files.xcfilelist",
			);
			runOnlyForDeploymentPostprocessing = 0;
			shellPath = /bin/sh;
			shellScript = "\"${PODS_ROOT}/Target Support Files/Pods-MerchantApp2/Pods-MerchantApp2-frameworks.sh\"\n";
			showEnvVarsInLog = 0;
		};
		C38B50BA6285516D6DCD4F65 /* [CP] Check Pods Manifest.lock */ = {
			isa = PBXShellScriptBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			inputFileListPaths = (
			);
			inputPaths = (
				"${PODS_PODFILE_DIR_PATH}/Podfile.lock",
				"${PODS_ROOT}/Manifest.lock",
			);
			name = "[CP] Check Pods Manifest.lock";
			outputFileListPaths = (
			);
			outputPaths = (
				"$(DERIVED_FILE_DIR)/Pods-MerchantApp2-checkManifestLockResult.txt",
			);
			runOnlyForDeploymentPostprocessing = 0;
			shellPath = /bin/sh;
			shellScript = "diff \"${PODS_PODFILE_DIR_PATH}/Podfile.lock\" \"${PODS_ROOT}/Manifest.lock\" > /dev/null\nif [ $? != 0 ] ; then\n    # print error to STDERR\n    echo \"error: The sandbox is not in sync with the Podfile.lock. Run 'pod install' or update your CocoaPods installation.\" >&2\n    exit 1\nfi\n# This output is used by Xcode 'outputs' to avoid re-running this script phase.\necho \"SUCCESS\" > \"${SCRIPT_OUTPUT_FILE_0}\"\n";
			showEnvVarsInLog = 0;
		};
		E235C05ADACE081382539298 /* [CP] Copy Pods Resources */ = {
			isa = PBXShellScriptBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			inputFileListPaths = (
				"${PODS_ROOT}/Target Support Files/Pods-MerchantApp2/Pods-MerchantApp2-resources-${CONFIGURATION}-input-files.xcfilelist",
			);
			name = "[CP] Copy Pods Resources";
			outputFileListPaths = (
				"${PODS_ROOT}/Target Support Files/Pods-MerchantApp2/Pods-MerchantApp2-resources-${CONFIGURATION}-output-files.xcfilelist",
			);
			runOnlyForDeploymentPostprocessing = 0;
			shellPath = /bin/sh;
			shellScript = "\"${PODS_ROOT}/Target Support Files/Pods-MerchantApp2/Pods-MerchantApp2-resources.sh\"\n";
			showEnvVarsInLog = 0;
		};
/* End PBXShellScriptBuildPhase section */

/* Begin PBXSourcesBuildPhase section */
		13B07F871A680F5B00A75B9A /* Sources */ = {
			isa = PBXSourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
				761780ED2CA45674006654EE /* AppDelegate.swift in Sources */,
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXSourcesBuildPhase section */

/* Begin PBXTargetDependency section */
		00E356F51AD99517003FC87E /* PBXTargetDependency */ = {
			isa = PBXTargetDependency;
			target = 13B07F861A680F5B00A75B9A /* MerchantApp2 */;
			targetProxy = 00E356F41AD99517003FC87E /* PBXContainerItemProxy */;
		};
/* End PBXTargetDependency section */

/* Begin XCBuildConfiguration section */
		13B07F941A680F5B00A75B9A /* Debug */ = {
			isa = XCBuildConfiguration;
			baseConfigurationReference = 3B4392A12AC88292D35C810B /* Pods-MerchantApp2.debug.xcconfig */;
			buildSettings = {
				ASSETCATALOG_COMPILER_APPICON_NAME = AppIcon;
				CLANG_ENABLE_MODULES = YES;
				CURRENT_PROJECT_VERSION = 1;
				ENABLE_BITCODE = NO;
				INFOPLIST_FILE = MerchantApp2/Info.plist;
				IPHONEOS_DEPLOYMENT_TARGET = 15.1;
				LD_RUNPATH_SEARCH_PATHS = (
					"$(inherited)",
					"@executable_path/Frameworks",
				);
				MARKETING_VERSION = 1.0;
				OTHER_LDFLAGS = (
					"$(inherited)",
					"-ObjC",
					"-lc++",
				);
				PRODUCT_BUNDLE_IDENTIFIER = "org.reactjs.native.example.$(PRODUCT_NAME:rfc1034identifier)";
				PRODUCT_NAME = MerchantApp2;
				SWIFT_OPTIMIZATION_LEVEL = "-Onone";
				SWIFT_VERSION = 5.0;
				VERSIONING_SYSTEM = "apple-generic";
			};
			name = Debug;
		};
		13B07F951A680F5B00A75B9A /* Release */ = {
			isa = XCBuildConfiguration;
			baseConfigurationReference = 5709B34CF0A7D63546082F79 /* Pods-MerchantApp2.release.xcconfig */;
			buildSettings = {
				ASSETCATALOG_COMPILER_APPICON_NAME = AppIcon;
				CLANG_ENABLE_MODULES = YES;
				CURRENT_PROJECT_VERSION = 1;
				INFOPLIST_FILE = MerchantApp2/Info.plist;
				IPHONEOS_DEPLOYMENT_TARGET = 15.1;
				LD_RUNPATH_SEARCH_PATHS = (
					"$(inherited)",
					"@executable_path/Frameworks",
				);
				MARKETING_VERSION = 1.0;
				OTHER_LDFLAGS = (
					"$(inherited)",
					"-ObjC",
					"-lc++",
				);
				PRODUCT_BUNDLE_IDENTIFIER = "org.reactjs.native.example.$(PRODUCT_NAME:rfc1034identifier)";
				PRODUCT_NAME = MerchantApp2;
				SWIFT_VERSION = 5.0;
				VERSIONING_SYSTEM = "apple-generic";
			};
			name = Release;
		};
		83CBBA201A601CBA00E9B192 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ALWAYS_SEARCH_USER_PATHS = NO;
				CLANG_ANALYZER_LOCALIZABILITY_NONLOCALIZED = YES;
				CLANG_CXX_LANGUAGE_STANDARD = "c++20";
				CLANG_CXX_LIBRARY = "libc++";
				CLANG_ENABLE_MODULES = YES;
				CLANG_ENABLE_OBJC_ARC = YES;
				CLANG_WARN_BLOCK_CAPTURE_AUTORELEASING = YES;
				CLANG_WARN_BOOL_CONVERSION = YES;
				CLANG_WARN_COMMA = YES;
				CLANG_WARN_CONSTANT_CONVERSION = YES;
				CLANG_WARN_DEPRECATED_OBJC_IMPLEMENTATIONS = YES;
				CLANG_WARN_DIRECT_OBJC_ISA_USAGE = YES_ERROR;
				CLANG_WARN_EMPTY_BODY = YES;
				CLANG_WARN_ENUM_CONVERSION = YES;
				CLANG_WARN_INFINITE_RECURSION = YES;
				CLANG_WARN_INT_CONVERSION = YES;
				CLANG_WARN_NON_LITERAL_NULL_CONVERSION = YES;
				CLANG_WARN_OBJC_IMPLICIT_RETAIN_SELF = YES;
				CLANG_WARN_OBJC_LITERAL_CONVERSION = YES;
				CLANG_WARN_OBJC_ROOT_CLASS = YES_ERROR;
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = YES;
				CLANG_WARN_RANGE_LOOP_ANALYSIS = YES;
				CLANG_WARN_STRICT_PROTOTYPES = YES;
				CLANG_WARN_SUSPICIOUS_MOVE = YES;
				CLANG_WARN_UNREACHABLE_CODE = YES;
				CLANG_WARN__DUPLICATE_METHOD_MATCH = YES;
				"CODE_SIGN_IDENTITY[sdk=iphoneos*]" = "iPhone Developer";
				COPY_PHASE_STRIP = NO;
				ENABLE_STRICT_OBJC_MSGSEND = YES;
				ENABLE_TESTABILITY = YES;
				"EXCLUDED_ARCHS[sdk=iphonesimulator*]" = "";
				GCC_C_LANGUAGE_STANDARD = gnu99;
				GCC_DYNAMIC_NO_PIC = NO;
				GCC_NO_COMMON_BLOCKS = YES;
				GCC_OPTIMIZATION_LEVEL = 0;
				GCC_PREPROCESSOR_DEFINITIONS = (
					"DEBUG=1",
					"$(inherited)",
				);
				GCC_SYMBOLS_PRIVATE_EXTERN = NO;
				GCC_WARN_64_TO_32_BIT_CONVERSION = YES;
				GCC_WARN_ABOUT_RETURN_TYPE = YES_ERROR;
				GCC_WARN_UNDECLARED_SELECTOR = YES;
				GCC_WARN_UNINITIALIZED_AUTOS = YES_AGGRESSIVE;
				GCC_WARN_UNUSED_FUNCTION = YES;
				GCC_WARN_UNUSED_VARIABLE = YES;
				IPHONEOS_DEPLOYMENT_TARGET = 15.1;
				LD_RUNPATH_SEARCH_PATHS = (
					/usr/lib/swift,
					"$(inherited)",
				);
				LIBRARY_SEARCH_PATHS = (
					"\"$(SDKROOT)/usr/lib/swift\"",
					"\"$(TOOLCHAIN_DIR)/usr/lib/swift/$(PLATFORM_NAME)\"",
					"\"$(inherited)\"",
				);
				MTL_ENABLE_DEBUG_INFO = YES;
				ONLY_ACTIVE_ARCH = YES;
				OTHER_CPLUSPLUSFLAGS = (
					"$(OTHER_CFLAGS)",
					"-DFOLLY_NO_CONFIG",
					"-DFOLLY_MOBILE=1",
					"-DFOLLY_USE_LIBCPP=1",
					"-DFOLLY_CFG_NO_COROUTINES=1",
					"-DFOLLY_HAVE_CLOCK_GETTIME=1",
				);
				SDKROOT = iphoneos;
			};
			name = Debug;
		};
		83CBBA211A601CBA00E9B192 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ALWAYS_SEARCH_USER_PATHS = NO;
				CLANG_ANALYZER_LOCALIZABILITY_NONLOCALIZED = YES;
				CLANG_CXX_LANGUAGE_STANDARD = "c++20";
				CLANG_CXX_LIBRARY = "libc++";
				CLANG_ENABLE_MODULES = YES;
				CLANG_ENABLE_OBJC_ARC = YES;
				CLANG_WARN_BLOCK_CAPTURE_AUTORELEASING = YES;
				CLANG_WARN_BOOL_CONVERSION = YES;
				CLANG_WARN_COMMA = YES;
				CLANG_WARN_CONSTANT_CONVERSION = YES;
				CLANG_WARN_DEPRECATED_OBJC_IMPLEMENTATIONS = YES;
				CLANG_WARN_DIRECT_OBJC_ISA_USAGE = YES_ERROR;
				CLANG_WARN_EMPTY_BODY = YES;
				CLANG_WARN_ENUM_CONVERSION = YES;
				CLANG_WARN_INFINITE_RECURSION = YES;
				CLANG_WARN_INT_CONVERSION = YES;
				CLANG_WARN_NON_LITERAL_NULL_CONVERSION = YES;
				CLANG_WARN_OBJC_IMPLICIT_RETAIN_SELF = YES;
				CLANG_WARN_OBJC_LITERAL_CONVERSION = YES;
				CLANG_WARN_OBJC_ROOT_CLASS = YES_ERROR;
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = YES;
				CLANG_WARN_RANGE_LOOP_ANALYSIS = YES;
				CLANG_WARN_STRICT_PROTOTYPES = YES;
				CLANG_WARN_SUSPICIOUS_MOVE = YES;
				CLANG_WARN_UNREACHABLE_CODE = YES;
				CLANG_WARN__DUPLICATE_METHOD_MATCH = YES;
				"CODE_SIGN_IDENTITY[sdk=iphoneos*]" = "iPhone Developer";
				COPY_PHASE_STRIP = YES;
				ENABLE_NS_ASSERTIONS = NO;
				ENABLE_STRICT_OBJC_MSGSEND = YES;
				"EXCLUDED_ARCHS[sdk=iphonesimulator*]" = "";
				GCC_C_LANGUAGE_STANDARD = gnu99;
				GCC_NO_COMMON_BLOCKS = YES;
				GCC_WARN_64_TO_32_BIT_CONVERSION = YES;
				GCC_WARN_ABOUT_RETURN_TYPE = YES_ERROR;
				GCC_WARN_UNDECLARED_SELECTOR = YES;
				GCC_WARN_UNINITIALIZED_AUTOS = YES_AGGRESSIVE;
				GCC_WARN_UNUSED_FUNCTION = YES;
				GCC_WARN_UNUSED_VARIABLE = YES;
				IPHONEOS_DEPLOYMENT_TARGET = 15.1;
				LD_RUNPATH_SEARCH_PATHS = (
					/usr/lib/swift,
					"$(inherited)",
				);
				LIBRARY_SEARCH_PATHS = (
					"\"$(SDKROOT)/usr/lib/swift\"",
					"\"$(TOOLCHAIN_DIR)/usr/lib/swift/$(PLATFORM_NAME)\"",
					"\"$(inherited)\"",
				);
				MTL_ENABLE_DEBUG_INFO = NO;
				OTHER_CPLUSPLUSFLAGS = (
					"$(OTHER_CFLAGS)",
					"-DFOLLY_NO_CONFIG",
					"-DFOLLY_MOBILE=1",
					"-DFOLLY_USE_LIBCPP=1",
					"-DFOLLY_CFG_NO_COROUTINES=1",
					"-DFOLLY_HAVE_CLOCK_GETTIME=1",
				);
				SDKROOT = iphoneos;
				VALIDATE_PRODUCT = YES;
			};
			name = Release;
		};
/* End XCBuildConfiguration section */

/* Begin XCConfigurationList section */
		13B07F931A680F5B00A75B9A /* Build configuration list for PBXNativeTarget "MerchantApp2" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				13B07F941A680F5B00A75B9A /* Debug */,
				13B07F951A680F5B00A75B9A /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
		83CBB9FA1A601CBA00E9B192 /* Build configuration list for PBXProject "MerchantApp2" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				83CBBA201A601CBA00E9B192 /* Debug */,
				83CBBA211A601CBA00E9B192 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
/* End XCConfigurationList section */
	};
	rootObject = 83CBB9F71A601CBA00E9B192 /* Project object */;
}
</file>

<file path="ios/MerchantApp2.xcodeproj/xcshareddata/xcschemes/MerchantApp2.xcscheme">
<?xml version="1.0" encoding="UTF-8"?>
<Scheme
   LastUpgradeVersion = "1210"
   version = "1.3">
   <BuildAction
      parallelizeBuildables = "YES"
      buildImplicitDependencies = "YES">
      <BuildActionEntries>
         <BuildActionEntry
            buildForTesting = "YES"
            buildForRunning = "YES"
            buildForProfiling = "YES"
            buildForArchiving = "YES"
            buildForAnalyzing = "YES">
            <BuildableReference
               BuildableIdentifier = "primary"
               BlueprintIdentifier = "13B07F861A680F5B00A75B9A"
               BuildableName = "MerchantApp2.app"
               BlueprintName = "MerchantApp2"
               ReferencedContainer = "container:MerchantApp2.xcodeproj">
            </BuildableReference>
         </BuildActionEntry>
      </BuildActionEntries>
   </BuildAction>
   <TestAction
      buildConfiguration = "Debug"
      selectedDebuggerIdentifier = "Xcode.DebuggerFoundation.Debugger.LLDB"
      selectedLauncherIdentifier = "Xcode.DebuggerFoundation.Launcher.LLDB"
      shouldUseLaunchSchemeArgsEnv = "YES">
      <Testables>
         <TestableReference
            skipped = "NO">
            <BuildableReference
               BuildableIdentifier = "primary"
               BlueprintIdentifier = "00E356ED1AD99517003FC87E"
               BuildableName = "MerchantApp2Tests.xctest"
               BlueprintName = "MerchantApp2Tests"
               ReferencedContainer = "container:MerchantApp2.xcodeproj">
            </BuildableReference>
         </TestableReference>
      </Testables>
   </TestAction>
   <LaunchAction
      buildConfiguration = "Debug"
      selectedDebuggerIdentifier = "Xcode.DebuggerFoundation.Debugger.LLDB"
      selectedLauncherIdentifier = "Xcode.DebuggerFoundation.Launcher.LLDB"
      launchStyle = "0"
      useCustomWorkingDirectory = "NO"
      ignoresPersistentStateOnLaunch = "NO"
      debugDocumentVersioning = "YES"
      debugServiceExtension = "internal"
      allowLocationSimulation = "YES">
      <BuildableProductRunnable
         runnableDebuggingMode = "0">
         <BuildableReference
            BuildableIdentifier = "primary"
            BlueprintIdentifier = "13B07F861A680F5B00A75B9A"
            BuildableName = "MerchantApp2.app"
            BlueprintName = "MerchantApp2"
            ReferencedContainer = "container:MerchantApp2.xcodeproj">
         </BuildableReference>
      </BuildableProductRunnable>
   </LaunchAction>
   <ProfileAction
      buildConfiguration = "Release"
      shouldUseLaunchSchemeArgsEnv = "YES"
      savedToolIdentifier = ""
      useCustomWorkingDirectory = "NO"
      debugDocumentVersioning = "YES">
      <BuildableProductRunnable
         runnableDebuggingMode = "0">
         <BuildableReference
            BuildableIdentifier = "primary"
            BlueprintIdentifier = "13B07F861A680F5B00A75B9A"
            BuildableName = "MerchantApp2.app"
            BlueprintName = "MerchantApp2"
            ReferencedContainer = "container:MerchantApp2.xcodeproj">
         </BuildableReference>
      </BuildableProductRunnable>
   </ProfileAction>
   <AnalyzeAction
      buildConfiguration = "Debug">
   </AnalyzeAction>
   <ArchiveAction
      buildConfiguration = "Release"
      revealArchiveInOrganizer = "YES">
   </ArchiveAction>
</Scheme>
</file>

<file path="ios/MerchantApp2/AppDelegate.swift">
import UIKit
import React
import React_RCTAppDelegate
import ReactAppDependencyProvider

@main
class AppDelegate: UIResponder, UIApplicationDelegate {
  var window: UIWindow?

  var reactNativeDelegate: ReactNativeDelegate?
  var reactNativeFactory: RCTReactNativeFactory?

  func application(
    _ application: UIApplication,
    didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]? = nil
  ) -> Bool {
    let delegate = ReactNativeDelegate()
    let factory = RCTReactNativeFactory(delegate: delegate)
    delegate.dependencyProvider = RCTAppDependencyProvider()

    reactNativeDelegate = delegate
    reactNativeFactory = factory

    window = UIWindow(frame: UIScreen.main.bounds)

    factory.startReactNative(
      withModuleName: "MerchantApp2",
      in: window,
      launchOptions: launchOptions
    )

    return true
  }
}

class ReactNativeDelegate: RCTDefaultReactNativeFactoryDelegate {
  override func sourceURL(for bridge: RCTBridge) -> URL? {
    self.bundleURL()
  }

  override func bundleURL() -> URL? {
#if DEBUG
    RCTBundleURLProvider.sharedSettings().jsBundleURL(forBundleRoot: "index")
#else
    Bundle.main.url(forResource: "main", withExtension: "jsbundle")
#endif
  }
}
</file>

<file path="ios/MerchantApp2/Images.xcassets/AppIcon.appiconset/Contents.json">
{
  "images" : [
    {
      "idiom" : "iphone",
      "scale" : "2x",
      "size" : "20x20"
    },
    {
      "idiom" : "iphone",
      "scale" : "3x",
      "size" : "20x20"
    },
    {
      "idiom" : "iphone",
      "scale" : "2x",
      "size" : "29x29"
    },
    {
      "idiom" : "iphone",
      "scale" : "3x",
      "size" : "29x29"
    },
    {
      "idiom" : "iphone",
      "scale" : "2x",
      "size" : "40x40"
    },
    {
      "idiom" : "iphone",
      "scale" : "3x",
      "size" : "40x40"
    },
    {
      "idiom" : "iphone",
      "scale" : "2x",
      "size" : "60x60"
    },
    {
      "idiom" : "iphone",
      "scale" : "3x",
      "size" : "60x60"
    },
    {
      "idiom" : "ios-marketing",
      "scale" : "1x",
      "size" : "1024x1024"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}
</file>

<file path="ios/MerchantApp2/Images.xcassets/Contents.json">
{
  "info" : {
    "version" : 1,
    "author" : "xcode"
  }
}
</file>

<file path="ios/MerchantApp2/Info.plist">
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>CFBundleDevelopmentRegion</key>
	<string>en</string>
	<key>CFBundleDisplayName</key>
	<string>MerchantApp2</string>
	<key>CFBundleExecutable</key>
	<string>$(EXECUTABLE_NAME)</string>
	<key>CFBundleIdentifier</key>
	<string>$(PRODUCT_BUNDLE_IDENTIFIER)</string>
	<key>CFBundleInfoDictionaryVersion</key>
	<string>6.0</string>
	<key>CFBundleName</key>
	<string>$(PRODUCT_NAME)</string>
	<key>CFBundlePackageType</key>
	<string>APPL</string>
	<key>CFBundleShortVersionString</key>
	<string>$(MARKETING_VERSION)</string>
	<key>CFBundleSignature</key>
	<string>????</string>
	<key>CFBundleVersion</key>
	<string>$(CURRENT_PROJECT_VERSION)</string>
	<key>LSRequiresIPhoneOS</key>
	<true/>
	<key>NSAppTransportSecurity</key>
	<dict>
	  <!-- Do not change NSAllowsArbitraryLoads to true, or you will risk app rejection! -->
		<key>NSAllowsArbitraryLoads</key>
		<false/>
		<key>NSAllowsLocalNetworking</key>
		<true/>
	</dict>
	<key>NSCameraUsageDescription</key>
	<string>This app needs camera access to scan QR codes</string>
	<key>NSLocationWhenInUseUsageDescription</key>
	<string></string>
	<key>UILaunchStoryboardName</key>
	<string>LaunchScreen</string>
	<key>UIRequiredDeviceCapabilities</key>
	<array>
		<string>arm64</string>
	</array>
	<key>UISupportedInterfaceOrientations</key>
	<array>
		<string>UIInterfaceOrientationPortrait</string>
		<string>UIInterfaceOrientationLandscapeLeft</string>
		<string>UIInterfaceOrientationLandscapeRight</string>
	</array>
	<key>UIViewControllerBasedStatusBarAppearance</key>
	<false/>
</dict>
</plist>
</file>

<file path="ios/MerchantApp2/LaunchScreen.storyboard">
<?xml version="1.0" encoding="UTF-8"?>
<document type="com.apple.InterfaceBuilder3.CocoaTouch.Storyboard.XIB" version="3.0" toolsVersion="15702" targetRuntime="iOS.CocoaTouch" propertyAccessControl="none" useAutolayout="YES" launchScreen="YES" useTraitCollections="YES" useSafeAreas="YES" colorMatched="YES" initialViewController="01J-lp-oVM">
    <device id="retina4_7" orientation="portrait" appearance="light"/>
    <dependencies>
        <deployment identifier="iOS"/>
        <plugIn identifier="com.apple.InterfaceBuilder.IBCocoaTouchPlugin" version="15704"/>
        <capability name="Safe area layout guides" minToolsVersion="9.0"/>
        <capability name="documents saved in the Xcode 8 format" minToolsVersion="8.0"/>
    </dependencies>
    <scenes>
        <!--View Controller-->
        <scene sceneID="EHf-IW-A2E">
            <objects>
                <viewController id="01J-lp-oVM" sceneMemberID="viewController">
                    <view key="view" contentMode="scaleToFill" id="Ze5-6b-2t3">
                        <rect key="frame" x="0.0" y="0.0" width="375" height="667"/>
                        <autoresizingMask key="autoresizingMask" widthSizable="YES" heightSizable="YES"/>
                        <subviews>
                            <label opaque="NO" clipsSubviews="YES" userInteractionEnabled="NO" contentMode="left" horizontalHuggingPriority="251" verticalHuggingPriority="251" text="MerchantApp2" textAlignment="center" lineBreakMode="middleTruncation" baselineAdjustment="alignBaselines" minimumFontSize="18" translatesAutoresizingMaskIntoConstraints="NO" id="GJd-Yh-RWb">
                                <rect key="frame" x="0.0" y="202" width="375" height="43"/>
                                <fontDescription key="fontDescription" type="boldSystem" pointSize="36"/>
                                <nil key="highlightedColor"/>
                            </label>
                            <label opaque="NO" clipsSubviews="YES" userInteractionEnabled="NO" contentMode="left" horizontalHuggingPriority="251" verticalHuggingPriority="251" text="Powered by React Native" textAlignment="center" lineBreakMode="tailTruncation" baselineAdjustment="alignBaselines" minimumFontSize="9" translatesAutoresizingMaskIntoConstraints="NO" id="MN2-I3-ftu">
                                <rect key="frame" x="0.0" y="626" width="375" height="21"/>
                                <fontDescription key="fontDescription" type="system" pointSize="17"/>
                                <nil key="highlightedColor"/>
                            </label>
                        </subviews>
                        <color key="backgroundColor" systemColor="systemBackgroundColor" cocoaTouchSystemColor="whiteColor"/>
                        <constraints>
                            <constraint firstItem="Bcu-3y-fUS" firstAttribute="bottom" secondItem="MN2-I3-ftu" secondAttribute="bottom" constant="20" id="OZV-Vh-mqD"/>
                            <constraint firstItem="Bcu-3y-fUS" firstAttribute="centerX" secondItem="GJd-Yh-RWb" secondAttribute="centerX" id="Q3B-4B-g5h"/>
                            <constraint firstItem="MN2-I3-ftu" firstAttribute="centerX" secondItem="Bcu-3y-fUS" secondAttribute="centerX" id="akx-eg-2ui"/>
                            <constraint firstItem="MN2-I3-ftu" firstAttribute="leading" secondItem="Bcu-3y-fUS" secondAttribute="leading" id="i1E-0Y-4RG"/>
                            <constraint firstItem="GJd-Yh-RWb" firstAttribute="centerY" secondItem="Ze5-6b-2t3" secondAttribute="bottom" multiplier="1/3" constant="1" id="moa-c2-u7t"/>
                            <constraint firstItem="GJd-Yh-RWb" firstAttribute="leading" secondItem="Bcu-3y-fUS" secondAttribute="leading" symbolic="YES" id="x7j-FC-K8j"/>
                        </constraints>
                        <viewLayoutGuide key="safeArea" id="Bcu-3y-fUS"/>
                    </view>
                </viewController>
                <placeholder placeholderIdentifier="IBFirstResponder" id="iYj-Kq-Ea1" userLabel="First Responder" sceneMemberID="firstResponder"/>
            </objects>
            <point key="canvasLocation" x="52.173913043478265" y="375"/>
        </scene>
    </scenes>
</document>
</file>

<file path="ios/MerchantApp2/PrivacyInfo.xcprivacy">
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyAccessedAPITypes</key>
	<array>
		<dict>
			<key>NSPrivacyAccessedAPIType</key>
			<string>NSPrivacyAccessedAPICategoryFileTimestamp</string>
			<key>NSPrivacyAccessedAPITypeReasons</key>
			<array>
				<string>C617.1</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyAccessedAPIType</key>
			<string>NSPrivacyAccessedAPICategoryUserDefaults</string>
			<key>NSPrivacyAccessedAPITypeReasons</key>
			<array>
				<string>CA92.1</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyAccessedAPIType</key>
			<string>NSPrivacyAccessedAPICategorySystemBootTime</string>
			<key>NSPrivacyAccessedAPITypeReasons</key>
			<array>
				<string>35F9.1</string>
			</array>
		</dict>
	</array>
	<key>NSPrivacyCollectedDataTypes</key>
	<array/>
	<key>NSPrivacyTracking</key>
	<false/>
</dict>
</plist>
</file>

<file path="ios/Podfile">
# Resolve react_native_pods.rb with node to allow for hoisting
require Pod::Executable.execute_command('node', ['-p',
  'require.resolve(
    "react-native/scripts/react_native_pods.rb",
    {paths: [process.argv[1]]},
  )', __dir__]).strip

platform :ios, min_ios_version_supported
prepare_react_native_project!

linkage = ENV['USE_FRAMEWORKS']
if linkage != nil
  Pod::UI.puts "Configuring Pod with #{linkage}ally linked Frameworks".green
  use_frameworks! :linkage => linkage.to_sym
end

target 'MerchantApp2' do
  config = use_native_modules!

  use_react_native!(
    :path => config[:reactNativePath],
    # An absolute path to your application root.
    :app_path => "#{Pod::Config.instance.installation_root}/.."
  )

  post_install do |installer|
    # https://github.com/facebook/react-native/blob/main/packages/react-native/scripts/react_native_pods.rb#L197-L202
    react_native_post_install(
      installer,
      config[:reactNativePath],
      :mac_catalyst_enabled => false,
      # :ccache_enabled => true
    )
  end
end
</file>

<file path="jest.config.js">
module.exports = {
  preset: 'react-native',
};
</file>

<file path="metro.config.js">
const { getDefaultConfig, mergeConfig } = require('@react-native/metro-config');

/**
 * Metro configuration
 * https://reactnative.dev/docs/metro
 *
 * @type {import('@react-native/metro-config').MetroConfig}
 */
const config = {};

module.exports = mergeConfig(getDefaultConfig(__dirname), config);
</file>

<file path="package.json">
{
  "name": "MerchantApp2",
  "version": "0.0.1",
  "private": true,
  "scripts": {
    "android": "react-native run-android",
    "ios": "react-native run-ios",
    "lint": "eslint .",
    "start": "react-native start",
    "test": "jest"
  },
  "dependencies": {
    "@react-native/new-app-screen": "0.80.2",
    "@react-navigation/native": "^7.1.17",
    "@react-navigation/stack": "^7.4.5",
    "@shopify/react-native-skia": "^2.2.2",
    "jsqr": "^1.4.0",
    "react": "19.1.0",
    "react-native": "0.80.2",
    "react-native-gesture-handler": "^2.28.0",
    "react-native-reanimated": "^3.19.0",
    "react-native-safe-area-context": "^5.6.0",
    "react-native-screens": "^4.13.1",
    "react-native-vision-camera": "^4.7.1",
    "react-native-worklets-core": "^1.6.2"
  },
  "devDependencies": {
    "@babel/core": "^7.25.2",
    "@babel/preset-env": "^7.25.3",
    "@babel/runtime": "^7.25.0",
    "@react-native-community/cli": "19.1.1",
    "@react-native-community/cli-platform-android": "19.1.1",
    "@react-native-community/cli-platform-ios": "19.1.1",
    "@react-native/babel-preset": "0.80.2",
    "@react-native/eslint-config": "0.80.2",
    "@react-native/metro-config": "0.80.2",
    "@react-native/typescript-config": "0.80.2",
    "@types/jest": "^29.5.13",
    "@types/react": "^19.1.0",
    "@types/react-test-renderer": "^19.1.0",
    "eslint": "^8.19.0",
    "jest": "^29.6.3",
    "prettier": "2.8.8",
    "react-test-renderer": "19.1.0",
    "typescript": "5.0.4"
  },
  "engines": {
    "node": ">=18"
  }
}
</file>

<file path="README.md">
# Merchant App - Student Payment Portal

A React Native merchant application that allows merchants to scan student QR codes and process payments.

## Features

- **Dashboard**: Main merchant interface with quick actions and statistics
- **QR Code Scanner**: Real-time QR code scanning for student identification
- **Payment Processing**: Student details display and payment processing
- **Mock API**: Simulated backend for testing student data and payments

## Student Data

The app includes mock data for 5 test students:

- **STU001**: John Smith (Computer Science) - $1,250.00 balance
- **STU002**: Sarah Johnson (Business Administration) - $850.50 balance
- **STU003**: Michael Chen (Engineering) - $2,100.75 balance
- **STU004**: Emily Davis (Arts & Humanities) - $675.25 balance
- **STU005**: David Wilson (Medicine) - $3,200.00 balance

## How to Test

### 1. Generate Test QR Codes

1. Go to any online QR code generator (e.g., qr-code-generator.com)
2. Encode one of the student IDs: `STU001`, `STU002`, `STU003`, `STU004`, or `STU005`
3. Generate the QR code image

### 2. Test the App Flow

1. **Start the app**: `npx react-native run-android`
2. **Navigate to Scanner**: Tap "üì± Scan Student QR Code" on the dashboard
3. **Scan QR Code**: Point camera at the generated QR code
4. **View Student Details**: App will fetch and display student information
5. **Process Payment**: Navigate to payment screen and process the transaction

## App Flow

```
Dashboard ‚Üí QR Scanner ‚Üí Payment Screen ‚Üí Success/Back to Dashboard
```

### Dashboard
- Overview of merchant activities
- Quick access to QR scanner
- Test QR codes information
- Recent transaction history

### QR Scanner
- Real-time camera scanning
- Student ID extraction from QR codes
- API call to fetch student details
- Navigation to payment screen

### Payment Screen
- Complete student information display
- Current balance and payment amount
- Payment processing with mock API
- Success/failure handling

## Technical Implementation

### Libraries Used
- `@react-navigation/native` & `@react-navigation/stack`: Navigation
- `react-native-qrcode-scanner`: QR code scanning
- `react-native-camera`: Camera functionality
- `react-native-safe-area-context`: Safe area handling

### Key Components
- **Dashboard**: Main merchant interface
- **QrScanner**: Camera-based QR code scanning
- **PaymentScreen**: Payment processing interface
- **Mock API**: Simulated backend services

### Data Flow
1. QR code contains student ID (e.g., "STU001")
2. Scanner extracts ID and calls `fetchStudentDetails()`
3. Mock API returns student data
4. App navigates to PaymentScreen with student details
5. Payment processing calls `processPayment()` API
6. Success/failure feedback to user

## Installation & Setup

### Prerequisites
- Node.js and npm
- React Native CLI
- Android Studio (for Android development)
- Xcode (for iOS development)

### Installation Steps

1. **Install dependencies**:
   ```bash
   npm install
   ```

2. **Install navigation dependencies**:
   ```bash
   npm install @react-navigation/native @react-navigation/stack react-native-screens react-native-safe-area-context
   ```

3. **For iOS** (if developing on macOS):
   ```bash
   cd ios && pod install
   ```

4. **Start Metro bundler**:
   ```bash
   npx react-native start
   ```

5. **Run on Android**:
   ```bash
   npx react-native run-android
   ```

6. **Run on iOS** (macOS only):
   ```bash
   npx react-native run-ios
   ```

## Testing QR Codes

### Method 1: Online QR Generator
1. Visit qr-code-generator.com
2. Enter student ID (e.g., "STU001")
3. Generate QR code
4. Scan with app

### Method 2: Mobile QR Generator Apps
- Use any QR code generator app
- Encode student ID as text
- Generate and scan

### Method 3: Physical QR Codes
- Print generated QR codes
- Test with physical scanning

## Mock API Details

### Student Data Structure
```typescript
interface Student {
  id: string;
  name: string;
  email: string;
  phone: string;
  department: string;
  balance: number;
  studentId: string;
  semester: string;
  year: string;
}
```

### API Endpoints (Mock)
- `fetchStudentDetails(studentId)`: Returns student information
- `processPayment(studentId, amount, method)`: Processes payment

## Troubleshooting

### Common Issues

1. **Camera Permission**: Ensure camera permissions are granted
2. **QR Code Not Detected**: Make sure QR code is clear and well-lit
3. **Navigation Issues**: Check that all navigation dependencies are installed
4. **Build Errors**: Clean and rebuild the project

### Build Commands
```bash
# Clean build
cd android && ./gradlew clean && cd ..
npx react-native run-android

# Reset cache
npx react-native start --reset-cache
```

## Future Enhancements

- Real backend API integration
- Payment gateway integration
- Transaction history
- Receipt generation
- Offline mode support
- Push notifications
- Analytics dashboard

## License

This project is for educational and testing purposes.
</file>

<file path="tsconfig.json">
{
  "extends": "@react-native/typescript-config"
}
</file>

</files>
